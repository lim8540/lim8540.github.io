<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <meta name="description" content="선형회귀(Linear Regresion)"> <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Baesan Blog" /> <!-- Begin Jekyll SEO tag v2.6.1 --> <title>선형회귀 | Baesan Blog</title> <meta name="generator" content="Jekyll v4.1.1" /> <meta property="og:title" content="선형회귀" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="선형회귀(Linear Regresion)" /> <meta property="og:description" content="선형회귀(Linear Regresion)" /> <link rel="canonical" href="http://localhost:4000/programmers/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80" /> <meta property="og:url" content="http://localhost:4000/programmers/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80" /> <meta property="og:site_name" content="Baesan Blog" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2021-01-05T00:00:00+09:00" /> <script type="application/ld+json"> {"url":"http://localhost:4000/programmers/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80","headline":"선형회귀","dateModified":"2021-01-05T00:00:00+09:00","datePublished":"2021-01-05T00:00:00+09:00","description":"선형회귀(Linear Regresion)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/programmers/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80"},"@type":"BlogPosting","@context":"https://schema.org"}</script> <!-- End Jekyll SEO tag --> <link rel="shortcut icon" href="/favicon.ico" type="image/icon"> <link rel="icon" href="/favicon.ico" type="image/icon"> <!-- stylesheets --> <link rel="stylesheet" type="text/css" href="/assets/css/base.css"> <link rel="stylesheet" type="text/css" href="/assets/css/simplePagination.css"> <link rel="stylesheet" type="text/css" href="/assets/css/highlight-theme.css"> <link rel="stylesheet" type="text/css" href="/assets/css/rouge-code.css"> <link rel="stylesheet" type="text/css" href="/assets/css/post.css"> <!-- javascripts --> <script type="text/javascript" src="/assets/js/jquery.js"></script> <!--[if lt IE 9]> <script src="/assets/js/html5shiv.js"></script> <![endif]--> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "AMS" } }, tex2jax: { inlineMath: [ ['$', '$'] ], displayMath: [ ['$$', '$$'] ], processEscapes: true, } }); MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) { alert("Math Processing Error: "+message[1]); }); MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) { alert("Math Processing Error: "+message[1]); }); </script> <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> </head> <!-- bare layout means not header and footer like resume --> <body> <header id="l-header"> <div class="container"> <div class="row logo"> <div class="col-lg-7"> <h1>BAESAN</h1> </div> <div class="col-lg-5"> <p>one liner one...</p> <p>one liner two...</p> </div> </div> <div class="row navicon"> <a href=""><i class="fa fa-navicon"></i></a> </div> <div class="row navbar"> <nav class="col-lg-8 col-md-8 col-xs-12"> <ul class="row"> <li class="col-lg-3"><a href="/">HOME</a></li> <li class="col-lg-3"> <ul class="subnav"> <a href="javascript:void(0)">POST</a> <li><a href="/category">CATEGORY</a></li> <li><a href="/tag">TAG</a></li> </ul> </li> <li class="col-lg-3"><a href="/series">SERIES</a></li> <li class="col-lg-3"><a href="/about">ABOUT</a></li> </ul> </nav> <div class="search col-lg-4 col-md-4 col-xs-12"> <form> <label for="search"></label> <input id="search-input" name="serach" type="text" placeholder="Search Blog Posts..."> <i class="fa fa-search"></i> </form> </div> </div> </div> </header> <section id="l-main"> <div class="container"> <div id="search-result-wrapper" class="hidden"> <h3>Search Results:</h3> <div id="search-result"></div> </div> <style> #search-result-wrapper { font-size: 2rem; background-color: #eee; padding: 5rem; padding-left: 31rem; margin-top: 1rem; margin-bottom: 1rem; box-shadow: 0 0 10px #999; border-radius: 5px; background: white; } #search-result { padding-left: 3rem; } @media (max-width: 1200px) { #search-result-wrapper { font-size: 1.7rem; padding: 2rem; } #search-result { padding-left: 1rem; } } @media (max-width: 768px) { #search-result-wrapper { margin-top: 24rem !important; } } </style> <script> $(document).ready(function() { input = $("#search-input"); wrapper = $("#search-result-wrapper"); wrapper.hide(); wrapper.removeClass("hidden"); input.on("keyup change", function() { if (! input.val()) { wrapper.slideUp("ease"); } else { wrapper.slideDown("ease"); } }); }); </script> <script src="/assets/js/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-result'), json: "/search.json" }); </script> <div class="row"> <div id="markdown-container" class="col-lg-9"> <header> <p id="post-title">선형회귀</p> <ul class="tags clearfix"> <li><i class="fa fa-tag"></i> K-digital training</li> <li><i class="fa fa-tag"></i> week5_day2</li> <li><i class="fa fa-tag"></i> ml_basics</li> <li><i class="fa fa-tag"></i> 선형회귀</li> </ul> <p id="post-meta"> posted on <b>05 Jan 2021</b> under category <b>programmers</b> </p> </header> <h2 id="선형회귀linear-regresion">선형회귀(Linear Regresion)</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span><span class="p">;</span> <span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div> <p>먼저, 주어진 데이터를 직선을 사용해 모델링 하는 방법을 살펴본다. 직선함수는 다음고 같은 형태를 가진다. <br /> $y = ax + b$ <br /> 여기서 a는 기울기(slope)이고 b는 y절편 (intercept)라고 불린다. <br /> 아래 그래프는 기울기가 2이고 y절편이 -5인 직선으로부터 생성된 데이터를 보여준다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">rng</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">5</span> <span class="o">+</span> <span class="n">rng</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.collections.PathCollection at 0x7fcb82128ed0&gt;
</code></pre></div></div> <p><img src="https://user-images.githubusercontent.com/51064261/103624985-a99bd300-4f7d-11eb-8d0c-10b267c0fbf9.png" alt="ML_Basics(Linear Regression)_2_1" /></p> <p>Scikit-Learn의 <strong>LinearRegression</strong> estimator를 사용해서 위 데이터를 가장 잘 표현하는 직선을 찾을 수 있다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="c1">#x[:,np.newaxis]는 x의 차원을 늘려주는 역할을 함. x의 shape는 (50,0) 새로운 shape는 (50,1)
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>

<span class="n">xfit</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">yfit</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xfit</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">yfit</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x7fcb83649690&gt;]
</code></pre></div></div> <p><img src="https://user-images.githubusercontent.com/51064261/103625268-14e5a500-4f7e-11eb-8dd7-320ed2b25755.png" alt="ML_Basics(Linear Regression)_4_1" /></p> <p>모델 학습이 끝난 후 학습된 파라미터들은 model.”파라미터이름”_의 형태로 저장된다. 기울기와 y절편은 아래와 같이 출력할 수 있다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Model slope: "</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Model intercept: "</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model slope:  2.027208810360695
Model intercept:  -4.998577085553202
</code></pre></div></div> <p>LinearRegression estimator는 위의 예제와 같은 1차원 입력뿐만 아니라 다차원 입력을 사용한 선형모델을 다룰 수 있다. 다차원 선형모델은 다음과 같은 형태를 가진다. <br /> $y = a_0 + a_1x_1 + a_2x_2 + …$ <br /> 기하학적으로 이것은 hyper-plane으로 데이터를 표현하는 것이라고 말할 수 있다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">rng</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[4.17022005e-01, 7.20324493e-01, 1.14374817e-04],
       [3.02332573e-01, 1.46755891e-01, 9.23385948e-02],
       [1.86260211e-01, 3.45560727e-01, 3.96767474e-01],
       [5.38816734e-01, 4.19194514e-01, 6.85219500e-01],
       [2.04452250e-01, 8.78117436e-01, 2.73875932e-02],
       [6.70467510e-01, 4.17304802e-01, 5.58689828e-01],
       [1.40386939e-01, 1.98101489e-01, 8.00744569e-01],
       [9.68261576e-01, 3.13424178e-01, 6.92322616e-01],
       [8.76389152e-01, 8.94606664e-01, 8.50442114e-02],
       [3.90547832e-02, 1.69830420e-01, 8.78142503e-01],
       [9.83468338e-02, 4.21107625e-01, 9.57889530e-01],
       [5.33165285e-01, 6.91877114e-01, 3.15515631e-01],
       [6.86500928e-01, 8.34625672e-01, 1.82882773e-02],
       [7.50144315e-01, 9.88861089e-01, 7.48165654e-01],
       [2.80443992e-01, 7.89279328e-01, 1.03226007e-01],
       [4.47893526e-01, 9.08595503e-01, 2.93614148e-01],
       [2.87775339e-01, 1.30028572e-01, 1.93669579e-02],
       [6.78835533e-01, 2.11628116e-01, 2.65546659e-01],
       [4.91573159e-01, 5.33625451e-02, 5.74117605e-01],
       [1.46728575e-01, 5.89305537e-01, 6.99758360e-01],
       [1.02334429e-01, 4.14055988e-01, 6.94400158e-01],
       [4.14179270e-01, 4.99534589e-02, 5.35896406e-01],
       [6.63794645e-01, 5.14889112e-01, 9.44594756e-01],
       [5.86555041e-01, 9.03401915e-01, 1.37474704e-01],
       [1.39276347e-01, 8.07391289e-01, 3.97676837e-01],
       [1.65354197e-01, 9.27508580e-01, 3.47765860e-01],
       [7.50812103e-01, 7.25997985e-01, 8.83306091e-01],
       [6.23672207e-01, 7.50942434e-01, 3.48898342e-01],
       [2.69927892e-01, 8.95886218e-01, 4.28091190e-01],
       [9.64840047e-01, 6.63441498e-01, 6.21695720e-01],
       [1.14745973e-01, 9.49489259e-01, 4.49912133e-01],
       [5.78389614e-01, 4.08136803e-01, 2.37026980e-01],
       [9.03379521e-01, 5.73679487e-01, 2.87032703e-03],
       [6.17144914e-01, 3.26644902e-01, 5.27058102e-01],
       [8.85942099e-01, 3.57269760e-01, 9.08535151e-01],
       [6.23360116e-01, 1.58212428e-02, 9.29437234e-01],
       [6.90896918e-01, 9.97322850e-01, 1.72340508e-01],
       [1.37135750e-01, 9.32595463e-01, 6.96818161e-01],
       [6.60001727e-02, 7.55463053e-01, 7.53876188e-01],
       [9.23024536e-01, 7.11524759e-01, 1.24270962e-01],
       [1.98801338e-02, 2.62109869e-02, 2.83064880e-02],
       [2.46211068e-01, 8.60027949e-01, 5.38831064e-01],
       [5.52821979e-01, 8.42030892e-01, 1.24173315e-01],
       [2.79183679e-01, 5.85759271e-01, 9.69595748e-01],
       [5.61030219e-01, 1.86472894e-02, 8.00632673e-01],
       [2.32974274e-01, 8.07105196e-01, 3.87860644e-01],
       [8.63541855e-01, 7.47121643e-01, 5.56240234e-01],
       [1.36455226e-01, 5.99176895e-02, 1.21343456e-01],
       [4.45518785e-02, 1.07494129e-01, 2.25709339e-01],
       [7.12988980e-01, 5.59716982e-01, 1.25559802e-02],
       [7.19742797e-02, 9.67276330e-01, 5.68100462e-01],
       [2.03293235e-01, 2.52325745e-01, 7.43825854e-01],
       [1.95429481e-01, 5.81358927e-01, 9.70019989e-01],
       [8.46828801e-01, 2.39847759e-01, 4.93769714e-01],
       [6.19955718e-01, 8.28980900e-01, 1.56791395e-01],
       [1.85762022e-02, 7.00221437e-02, 4.86345111e-01],
       [6.06329462e-01, 5.68851437e-01, 3.17362409e-01],
       [9.88616154e-01, 5.79745219e-01, 3.80141173e-01],
       [5.50948219e-01, 7.45334431e-01, 6.69232893e-01],
       [2.64919558e-01, 6.63348344e-02, 3.70084198e-01],
       [6.29717507e-01, 2.10174010e-01, 7.52755554e-01],
       [6.65364814e-02, 2.60315099e-01, 8.04754564e-01],
       [1.93434283e-01, 6.39460881e-01, 5.24670309e-01],
       [9.24807970e-01, 2.63296770e-01, 6.59610907e-02],
       [7.35065963e-01, 7.72178030e-01, 9.07815853e-01],
       [9.31972069e-01, 1.39515730e-02, 2.34362086e-01],
       [6.16778357e-01, 9.49016321e-01, 9.50176119e-01],
       [5.56653188e-01, 9.15606350e-01, 6.41566209e-01],
       [3.90007714e-01, 4.85990667e-01, 6.04310483e-01],
       [5.49547922e-01, 9.26181427e-01, 9.18733436e-01],
       [3.94875613e-01, 9.63262528e-01, 1.73955667e-01],
       [1.26329519e-01, 1.35079158e-01, 5.05662166e-01],
       [2.15248053e-02, 9.47970211e-01, 8.27115471e-01],
       [1.50189807e-02, 1.76196256e-01, 3.32063574e-01],
       [1.30996845e-01, 8.09490692e-01, 3.44736653e-01],
       [9.40107482e-01, 5.82014180e-01, 8.78831984e-01],
       [8.44734445e-01, 9.05392319e-01, 4.59880266e-01],
       [5.46346816e-01, 7.98603591e-01, 2.85718852e-01],
       [4.90253523e-01, 5.99110308e-01, 1.55332756e-02],
       [5.93481408e-01, 4.33676349e-01, 8.07360529e-01],
       [3.15244803e-01, 8.92888709e-01, 5.77857215e-01],
       [1.84010202e-01, 7.87929234e-01, 6.12031177e-01],
       [5.39092721e-02, 4.20193680e-01, 6.79068837e-01],
       [9.18601778e-01, 4.02024891e-04, 9.76759149e-01],
       [3.76580315e-01, 9.73783538e-01, 6.04716101e-01],
       [8.28845808e-01, 5.74711505e-01, 6.28076198e-01],
       [2.85576282e-01, 5.86833341e-01, 7.50021764e-01],
       [8.58313836e-01, 7.55082188e-01, 6.98057248e-01],
       [8.64479430e-01, 3.22680997e-01, 6.70788791e-01],
       [4.50873936e-01, 3.82102752e-01, 4.10811350e-01],
       [4.01479583e-01, 3.17383946e-01, 6.21919368e-01],
       [4.30247271e-01, 9.73802078e-01, 6.77800891e-01],
       [1.98569888e-01, 4.26701009e-01, 3.43346240e-01],
       [7.97638804e-01, 8.79998289e-01, 9.03841956e-01],
       [6.62719812e-01, 2.70208262e-01, 2.52366702e-01],
       [8.54897943e-01, 5.27714646e-01, 8.02161084e-01],
       [5.72488517e-01, 7.33142525e-01, 5.19011627e-01],
       [7.70883911e-01, 5.68857991e-01, 4.65709879e-01],
       [3.42688908e-01, 6.82093484e-02, 3.77924179e-01],
       [7.96260777e-02, 9.82817114e-01, 1.81612851e-01]])
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">rng</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="c1">#y = 100 by 3 행렬과 크기 3 열벡터의 행렬곱
</span><span class="n">y</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>

<span class="n">y</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([ -3.37986709,  10.74767891,  -6.09131716,   8.43244545,
        20.01412846,   4.1934773 ,  -0.35094038,   2.06439823,
        -3.49599876,  -4.43407273,   2.8045874 ,  11.73613282,
         1.84545434,  18.62297315,   7.66471539,   0.28201632,
        -7.04995534,   8.21217837,  10.46412826,   1.08135752,
        -3.20686456,   9.020925  ,   2.80718498,  -9.07917586,
        -8.38474873,   7.27658939,   6.68275817,   8.61155789,
        15.74770923,   2.81707056,  -5.40078872,  -0.95319755,
        16.24978318,  19.35543153,  -4.67346522,  14.97781827,
         9.02197798,   2.9820238 ,  12.62515506,  -0.28833735,
         1.24377741,  10.86442283, -11.98041792,  -2.54929231,
         0.76504876,  17.51417234,  -5.70313302,   6.26514634,
        -3.51841988,   1.35496684,  -2.08336832,  -5.88361643,
        10.86096322,  -4.9367356 ,  -3.88796154,  14.80808349,
        -1.1477796 ,  14.46665226,   0.216072  ,  -0.2871369 ,
         0.32925132,   8.34530304,   5.05066835,  12.7567254 ,
       -14.70672142,   4.87199645,  -8.65569584,  11.98873887,
        -7.85813283,   5.97030505,   7.85318327,  14.14196923,
        -1.12908267, -12.94332059,  -0.21645362,  -6.88756954,
        10.37750735,   1.5342091 ,  16.37077611,   1.52484819,
        13.39370183,  -3.83864459,   1.28380699,  15.36109386,
        -3.1072014 ,  11.8134319 ,   2.18534994,  19.0904709 ,
         3.3314668 ,  10.06412076,   8.62160201,  -8.14847679,
         6.97457881,  -2.33743702,   5.3325264 ,   9.44047459,
        -4.21867229,  -0.07298716,  15.37233961,   2.8022421 ])
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(100,)
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.5000000000000018
[ 1.5 -2.   1. ]
</code></pre></div></div> <p>y값들은 랜덤하게 생성된 3차원의 x값과 계수들([1.5, -2., 1.])을 곱함으로써 생성되었는데, linear regression을 통해서 이 계수들을 계산해낼 수 있다는 것을 알 수 있다.</p> <p>만약 데이터가 선형적인 관계를 가지고 있지 않다면?</p> <h2 id="선형-기저함수-모델linear-basis-function-models">선형 기저함수 모델(Linear Basis function Models)</h2> <p>비선형데이터를 선형함수로 모델링하는 한가지 망법은 기저함수(basis function)을 사용하는 것이다. <br /> 예를 들어, 다음과 같은 선형함수를 사용한다고 하자. <br /> $ y = a_0 + a_1x_1 + a_2x_2 + a_3x_3 + …$ <br /> 여기서 $x_1, x_2, x_3$등을 1차원 x로 부터 생성할 수 있다. $(x_n = f_n(x))$. $f_n$을 기저함수라고 부른다. <br /> 만약 $f_n(x) = x^n$라는 기저함수를 사용하면 최종적인 모델은 다음과 같을 것이다. <br /> $ y = a_0 + a_1x_1 + a_2x_2^2 + a_3x_3^3 + …$ <br /> 이 모델은 여전히 계수$(a_n)$에 관해서는 선형함수임을 기억하자. 따라서 1차원 변수인 x를 기저함수를 통해 다차원으로 확장시킴으로써 우리는 여전히 선형모델(linear regression)을 사용할 수 있게 된다.</p> <h3 id="다항-기저함수polynoial-basis-functions">다항 기저함수(Polynoial Basis Functions)</h3> <p>$f_n(x) = x^n$의 형태의 함수를 다항 기저함수라고 부른다. Scikit-Learn은 PolynomialFeatures이라는 transformer를 이미 포함하고 있다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">include_bias</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="n">poly</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">])</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[ 2.,  4.,  8.],
       [ 3.,  9., 27.],
       [ 4., 16., 64.]])
</code></pre></div></div> <p>PolynomialFeatures가 1차원 array를 3차원 array로 변환한 것을 볼 수 있다. 이렇게 변환된 데이터를 선형모델에 적용할 수 있다.</p> <p>7차원 변환을 적용해보자.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="n">poly_model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">7</span><span class="p">),</span>
                          <span class="n">LinearRegression</span><span class="p">())</span>
</code></pre></div></div> <p>다차원 변환을 사용하면 복잡한 데이터를 모델링할 수 있게 된다. 예를 들어 sine함수를 사용해서 데이터를 생성하고 모델링 해보자.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">rng</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">rng</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.collections.PathCollection at 0x7fcb8388af10&gt;
</code></pre></div></div> <p><img src="https://user-images.githubusercontent.com/51064261/103625297-2169fd80-4f7e-11eb-91b4-e92463bfdf4d.png" alt="ML_Basics(Linear Regression)_19_1" /></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">poly_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">yfit</span> <span class="o">=</span> <span class="n">poly_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xfit</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">yfit</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;matplotlib.lines.Line2D at 0x7fcb8389d110&gt;]
</code></pre></div></div> <p><img src="https://user-images.githubusercontent.com/51064261/103625337-2fb81980-4f7e-11eb-8962-887ace82447f.png" alt="ML_Basics(Linear Regression)_20_1" /></p> <h3 id="가우시안-기저함수gaussian-basis-functions">가우시안 기저함수(Gaussian Basis Functions)</h3> <p>다항 기저함수 외에 다른 기저함수를 사용해보자. 가우시안 기저함수는 다음과 같이 정의된다. <br /> $exp(- \frac {(x-u_j)^2}{2s^2})$ <br /> $u_j$는 함수의 위치, s는 폭을 결정한다. 주어진 데이터를 여러개의 가우시안 기저함수들의 합으로 표현하려고 시도할 수 있다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span>

<span class="k">class</span> <span class="nc">GaussianFeatures</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="s">"""Uniformly spaced Gaussian features for one-dimensional input"""</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">width_factor</span><span class="o">=</span><span class="mf">2.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">width_factor</span> <span class="o">=</span> <span class="n">width_factor</span>
    
    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">_gauss_basis</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">arg</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">width</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">arg</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="c1"># create N centers spread along the data range
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">centers_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="nb">min</span><span class="p">(),</span> <span class="n">X</span><span class="p">.</span><span class="nb">max</span><span class="p">(),</span> <span class="bp">self</span><span class="p">.</span><span class="n">N</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">width_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">width_factor</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">centers_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="p">.</span><span class="n">centers_</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">self</span>
        
    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">_gauss_basis</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="bp">self</span><span class="p">.</span><span class="n">centers_</span><span class="p">,</span>
                                 <span class="bp">self</span><span class="p">.</span><span class="n">width_</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
<span class="n">gauss_model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">GaussianFeatures</span><span class="p">(</span><span class="mi">20</span><span class="p">),</span>
                            <span class="n">LinearRegression</span><span class="p">())</span>
<span class="n">gauss_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">yfit</span> <span class="o">=</span> <span class="n">gauss_model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xfit</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">yfit</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">);</span>

</code></pre></div></div> <p><img src="https://user-images.githubusercontent.com/51064261/103625373-3e063580-4f7e-11eb-95b5-f37b05a24a77.png" alt="ML_Basics(Linear Regression)_22_0" /></p> <h3 id="규제화regularization">규제화(Regularization)</h3> <p>기저함수를 사용함으로써 복잡한 데이터를 모델링할 수 있게 되었지만 조심하지 않는다면 over-fitting이라는 다른 심각한 무제를 만날 수 있다! 예를들어, 너무 많은 개수의 가우시안 기저함수를 사용하게 되면 다음과 같이 될 수 있다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">GaussianFeatures</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span>
                            <span class="n">LinearRegression</span><span class="p">())</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">yfit</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xfit</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">yfit</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(-1.5, 1.5)
</code></pre></div></div> <p><img src="https://user-images.githubusercontent.com/51064261/103625379-3e9ecc00-4f7e-11eb-9e26-7375b0333e7b.png" alt="ML_Basics(Linear Regression)_24_1" /></p> <p>이 예제에서는 30개의 기저함수가 사용되었는데 모델이 필요이상으로 flexible해져서 데이터가 없는 곳에서는 극단적인 값을 가지는 것을 볼 수 있다. 기저함수의 계수들은 다음과 같이 확인할 수 있다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">basis_plot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">xfit</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xfit</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]))</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">'x'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">'y'</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="n">title</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">steps</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">centers_</span><span class="p">,</span>
               <span class="n">model</span><span class="p">.</span><span class="n">steps</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">].</span><span class="n">coef_</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">'basis location'</span><span class="p">,</span>
              <span class="n">ylabel</span><span class="o">=</span><span class="s">'coefficient'</span><span class="p">,</span>
              <span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    
<span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">GaussianFeatures</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">LinearRegression</span><span class="p">())</span>
<span class="n">basis_plot</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <p><img src="https://user-images.githubusercontent.com/51064261/103625381-3f376280-4f7e-11eb-9067-1d49bbf08013.png" alt="ML_Basics(Linear Regression)_26_0" /></p> <p>위 두번째 그래프는 각각의 가우시안 기저함수의 크기(계수값)을 보여주고 있다. Over-fitting이 일어나는 영역에서는 인접한 기저함수들의 값이 극단으로 가면서 서로 상쇄하는 현상이 일어난다. 따라서 큰 계수값에 대해 penalty를 부여해서 over-fitting을 어느 정도 극복할 수 있을 것이다. 이러한 penalty를 regularization이라 부른다.</p> <h3 id="ridge-regressionl2-regularization">Ridge regression(L2 Regularization)</h3> <p>가장 자주 쓰이는 형태의 regularization은 ridge regression(L2 regularization)이고 다음과 같이 정의된다. <br /> $ P = \alpha \sum_{n=1}^N \theta_n^2$ <br /> 여기서 $\alpha$는 regularization의 강도를 조절하는 파라미터이다. 이 형태의 regularization은 Scikit-Learn의 Ridge estimator에서 사용된다.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">GaussianFeatures</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">basis_plot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">'Ridge Regression'</span><span class="p">)</span>
</code></pre></div></div> <p><img src="https://user-images.githubusercontent.com/51064261/103625383-3fcff900-4f7e-11eb-8c1e-772227543fb7.png" alt="ML_Basics(Linear Regression)_29_0" /></p> <p>$\alpha$값이 0에 가까워질수록 일반적인 선형회귀모델이 되고, $\alpha$값이 무한대로 증가하면 데이터는 모델에 영향을 주지 않게 된다.</p> <h3 id="lasso-regression-l1-regularization">Lasso Regression (L1 Regularization)</h3> <p>또 하나의 자주 쓰이는 regularization 방법은 계수들의 절대값의 합을 제한하는 것이다. <br /> $ P = \alpha \sum_{n=1}^N \vert \theta_n \vert $ <br /> 뒤에서 자세히 다루겠지만 이 방법은 sparse한 모델을 생성하게 된다.(많은계수들이 0이됨)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">GaussianFeatures</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">))</span>
<span class="n">basis_plot</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">'Lasso Regression'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/Users/sumin/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.002135815870488389, tolerance: 0.002065280097246271
  positive)
</code></pre></div></div> <p><img src="https://user-images.githubusercontent.com/51064261/103625384-40688f80-4f7e-11eb-9ab3-6cd08c3d27dd.png" alt="ML_Basics(Linear Regression)_32_1" /></p> <p>위에서 볼 수 있듯 대부분의 계수값들이 0이 된다. Ridge regression과 마찬가지로 $\alpha$값으로 regularization의 강도를 조절할 수 있다.</p> <h3 id="sgd">SGD</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDRegressor</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">GaussianFeatures</span><span class="p">(</span><span class="mi">30</span><span class="p">),</span>
                     <span class="n">SGDRegressor</span><span class="p">(</span><span class="n">max_iter</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">basis_plot</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/Users/sumin/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:1185: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning)
</code></pre></div></div> <p><img src="https://user-images.githubusercontent.com/51064261/103625389-40688f80-4f7e-11eb-8123-19ab1c2a7200.png" alt="ML_Basics(Linear Regression)_35_1" /></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div> </div> <div id="markdown-outline" class="col-lg-3"> </div> </div> </div> </section> <footer id="l-footer"> <div class="container"> <div class="row"> <div id="social" class="col-lg-5 col-md-5 col-sm-12"> <h3>SOCIAL</h3> <ul> <li> <i class="fa fa-github-square" title="GitHub"></i> <a href="https://github.com">&nbsp;&nbsp;https://github.com</a> </li> </ul> </div> <div id="contact" class="col-lg-4 col-md-4 col-sm-12"> <h3>CONTACT</h3> <ul> <li> <i class="fa fa-phone-square" title="Mobile"></i> <a href="tel: 123 4567 8010">&nbsp;&nbsp;123 4567 8910</a> </li> <li> <i class="fa fa-envelope" title="Email"></i> <a href="mailto: example@example.com">&nbsp;&nbsp;example@example.com</a> </li> </ul> </div> <div id="rss" class="col-lg-3 col-md-3 col-sm-12"> <h3>SUBSCRIBE</h3> <a href="/feed.xml"> <i class="rss fa fa-rss-square"></i> </a> </div> </div> <p id="legal"> Copyright (c) 2021 YOUR NAME | Powered by <a href="http://jekyllrb.com">Jekyll</a> &amp; <a href="http://github.com">GitHub</a> | designed &amp; build by <a href="http://unifreak.github.io">UniFreak</a><br /> The blog posts on this site are licensed under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>. </p> </div> </footer> <script type="text/javascript" src="/assets/js/base.js"></script> <!-- Global site tag (gtag.js) - Google Analytics --> <div id="search-result-wrapper" class="hidden"> <h3>Search Results:</h3> <div id="search-result"></div> </div> <style> #search-result-wrapper { font-size: 2rem; background-color: #eee; padding: 5rem; padding-left: 31rem; margin-top: 1rem; margin-bottom: 1rem; box-shadow: 0 0 10px #999; border-radius: 5px; background: white; } #search-result { padding-left: 3rem; } @media (max-width: 1200px) { #search-result-wrapper { font-size: 1.7rem; padding: 2rem; } #search-result { padding-left: 1rem; } } @media (max-width: 768px) { #search-result-wrapper { margin-top: 24rem !important; } } </style> <script> $(document).ready(function() { input = $("#search-input"); wrapper = $("#search-result-wrapper"); wrapper.hide(); wrapper.removeClass("hidden"); input.on("keyup change", function() { if (! input.val()) { wrapper.slideUp("ease"); } else { wrapper.slideDown("ease"); } }); }); </script> <script src="/assets/js/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-result'), json: "/search.json" }); </script> <script type="text/javascript" src="/assets/js/post.js"></script> </body> </html>
