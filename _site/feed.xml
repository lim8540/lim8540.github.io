<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Baesan Blog</title>
    <description>Baesan's blog about developing</description>
    <link>http://localhost:4000http://localhost:4000/</link>
    <atom:link href="http://localhost:4000http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 12 Dec 2020 18:20:47 +0900</pubDate>
    <lastBuildDate>Sat, 12 Dec 2020 18:20:47 +0900</lastBuildDate>
    <generator>Jekyll v4.1.1</generator>
    
      <item>
        <title>인공지능수학(9)(추정)</title>
        <description>&lt;h2 id=&quot;추정&quot;&gt;추정&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;구간추정
    &lt;ul&gt;
      &lt;li&gt;모평균 $\mu$의 $100(1-\alpha)\%$ 신뢰구간(confidence interval)
        &lt;ul&gt;
          &lt;li&gt;$(\mu의 추정량) \pm z_{\alpha \over 2} (추정량의 표준편차)$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;정규분포에서 $\sigma$를 알 때,
        &lt;ul&gt;
          &lt;li&gt;$(\bar {x} - z_{\alpha / 2}{\sigma \over {\sqrt n}}  ,  \bar {x} + z_{\alpha / 2}{\sigma \over {\sqrt n}} )$&lt;/li&gt;
          &lt;li&gt;그러나 이 방법은 실용적이지 못하다: 정규분포가 아니거나 표준편차가 알려져 있지 않은 경우가 많다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;표본의 크기가 클 때, 중심극한 정리를 사용한다.
        &lt;ul&gt;
          &lt;li&gt;$(\mu의 추정량) \pm z_{\alpha \over 2} (추정량의 표준편차)$
            &lt;ul&gt;
              &lt;li&gt;$(\bar {x} - z_{\alpha / 2}{s \over {\sqrt n}}  ,  \bar {x} + z_{\alpha / 2}{s \over {\sqrt n}} )$&lt;/li&gt;
              &lt;li&gt;$s$ : 표본표준편차&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;예시 : 어떤 학교의 고1 남학생의 평균키를 추정하기 위해 36명을 표본으로 추출하여 그 표본평균과 표본표준편차를 계산하여 그 결과가 아래와 같았다.
      - $\bar {x} = 173.6, s = 3.6$
      - 평균키에 대한 95% 신뢰구간을 구하시오.
    &lt;ul&gt;
      &lt;li&gt;해결 :
        &lt;ul&gt;
          &lt;li&gt;$\alpha = 0.05$(95%신뢰수준이므로)&lt;/li&gt;
          &lt;li&gt;$z_{\alpha / 2} = z_{0.025} = 1.96$&lt;/li&gt;
          &lt;li&gt;$z_{\alpha / 2}{s \over {\sqrt n}} = 1.96 \times {3.6 \over 6} = 1.176$&lt;/li&gt;
          &lt;li&gt;95% 신뢰구간 : $(173.6 - 1.176, 173.6 + 1.176) = (172.4, 174.8)$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;데이터가 주어졌을 때, python으로 계산하기
        &lt;ul&gt;
          &lt;li&gt;어떤 농장에서 생산된 계란 30개의 표본의 무게는 다음과 같았다. 계란의 평균 무게에 대한 95% 신뢰 구간을 구하시오.&lt;/li&gt;
          &lt;li&gt;$w = [10.7, 11.7, 9.8, …]$
            &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;11.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;11.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;8.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;12.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;11.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;11.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;11.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;11.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;11.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;11.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;8.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;12.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;13.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xbar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddof&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.stats&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 전체 확률 1에서 오른쪽부분은 0.025를 뺀 부분의 z값
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zalpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;평균 %.2f, 표준편차: %.2f&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xbar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;평균&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.43&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;표준편차&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.11&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zalpha&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; zalpha)
zalpha : 1.959963984540054
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
            &lt;p&gt;따라서, 95% 신뢰 구간 : $(10.43 - 1.96 \times {1.11 \over {\sqrt 30}} , 10.43 + 1.96 \times {1.11 \over {\sqrt 30}}) = (10.033, 10.827)$&lt;/p&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;예시 2&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;대학교 1학년생의 흡연율을 조사하기 위해 150명을 랜덤하게 선택하여 흡연여부를 조사하였다. 이 중 48명이 흡연을 하고 있었다. 이 대학교 1학년생의 흡연율의 평균을 점추정하시오.&lt;/li&gt;
      &lt;li&gt;점 추정
        &lt;ul&gt;
          &lt;li&gt;확률변수 X:
            &lt;ul&gt;
              &lt;li&gt;n개의 표본에서 특정 속성을 갖는 표본의 개수&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;모비율 p의 점추정량
            &lt;ul&gt;
              &lt;li&gt;$\hat {p} = {x \over n}$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;$n = 150, X=48$&lt;/li&gt;
          &lt;li&gt;$\hat {p} = {X \over n} = {48 \over 150} = 0.32$&lt;/li&gt;
          &lt;li&gt;평균 흡연율은 32%로 추정됨&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;구간추정
        &lt;ul&gt;
          &lt;li&gt;n이 충분히 클 때($n\hat{p} \gt 5, n(1-{\hat p }) \gt 5$일 때를 의미)&lt;/li&gt;
          &lt;li&gt;$X \sim N(np,np(1-p))$&lt;/li&gt;
          &lt;li&gt;모비율 p의 $100(1-\alpha)\%$ 신뢰구간 (confidence interval) (증명생략)
            &lt;ul&gt;
              &lt;li&gt;$(\hat{p} - z_{\alpha \over 2} {\sqrt { {\hat {p} (1 - \hat {p}) } \over n} }, \hat{p} + z_{\alpha \over 2} {\sqrt { {\hat {p} (1 - \hat {p}) } \over n} })$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;${\sqrt { {\hat {p} (1 - \hat {p}) } \over n} } = {\sqrt { {(0.32) (0.68) } \over 150} } = 0.038$&lt;/li&gt;
          &lt;li&gt;$(0.32 - 1.96 \times 0.038, 0.32 + 1.96 \times 0.038) = (0.245, 0.395)$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 11 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(9)(%EC%B6%94%EC%A0%95)</link>
        <guid isPermaLink="true">http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(9)(%EC%B6%94%EC%A0%95)</guid>
        
        <category>K-digital training</category>
        
        <category>week2_day5</category>
        
        <category>인공지능 수학</category>
        
        
        <category>programmers</category>
        
      </item>
    
      <item>
        <title>인공지능수학(8)(표본분포)</title>
        <description>&lt;h2 id=&quot;표본푼보&quot;&gt;표본푼보&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;랜덤한 숫자 생성하기
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;546&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;749&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;982&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;877&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;839&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;533&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;234&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;790&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;652&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;199&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;표본 평균이 가질 수 있는 값도 하나의 확률 분포를 가짐
    &lt;ul&gt;
      &lt;li&gt;예) 50만명의 전국 고등학교 1학년 학생의 키를 조사하기 위해 1000명을 표본 조사할 때, 표본의 선택에 따라 표본의 평균이 달라진다. 따라서 표본 평균은 일종의 확률 변수라고 할 수 있다.&lt;/li&gt;
      &lt;li&gt;통계량의 확률 분포를 표본분포(sampling distribution)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;표본 평균
    &lt;ul&gt;
      &lt;li&gt;모평균을 알아내는데 쓰이는 통계량&lt;/li&gt;
      &lt;li&gt;표본 평균의 분포
        &lt;ul&gt;
          &lt;li&gt;$x_1, x_2, …, x_n$
            &lt;ul&gt;
              &lt;li&gt;평균 : $\mu$, 분산 : $\sigma ^2$&lt;/li&gt;
              &lt;li&gt;정규모집단에서 추출된 표본의 측정값&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;표본 평균
            &lt;ul&gt;
              &lt;li&gt;$\bar {x} = {1 \over n} \sum_1^nx_i$&lt;/li&gt;
              &lt;li&gt;$\bar {X} \sim N(\mu, {\sigma ^2 \over n})$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 10개짜리 랜덤 추출한 표본의 평균 10000개
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xbars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rang&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# xbars(표본의 평균들)의 평균
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xbars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# xbars(표본의 평균들)의 분산
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xbars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;중심 극한 정리(central limit theorem)
    &lt;ul&gt;
      &lt;li&gt;$x_1, x_2, …, x_n$
        &lt;ul&gt;
          &lt;li&gt;평균 : $\mu$, 분산 : $\sigma ^2$&lt;/li&gt;
          &lt;li&gt;&lt;del&gt;정규&lt;/del&gt;모집단에서 추출된 표본의 측정값&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;표본 평균
        &lt;ul&gt;
          &lt;li&gt;$\bar {x} = {1 \over n} \sum_1^nx_i$&lt;/li&gt;
          &lt;li&gt;$n$이 충분히 큰 경우 $(n \ge 30)$,
            &lt;ul&gt;
              &lt;li&gt;근사적으로, $\bar {X} \sim N(\mu, {\sigma ^2 \over n})$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# 표본의 개수는 3
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# 0~10까지의 수에서 랜덤으로 3개를 뽑았을 때의 평균값을 10000개 뽑음
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xbars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pyplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xbars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;n 이 3일 때,
  &lt;img src=&quot;https://user-images.githubusercontent.com/51064261/101873524-6cd0fc00-3bca-11eb-9aab-f146f11d577d.png&quot; alt=&quot;다운로드&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;n 이 30일 때,
  &lt;img src=&quot;https://user-images.githubusercontent.com/51064261/101873903-2c25b280-3bcb-11eb-9a47-89da981ad022.png&quot; alt=&quot;n30&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;n의 값이 커질 수록 정규분포에 가까워짐을 알 수 있다. &lt;br /&gt;
  지수분포도 마찬가지의 결과를 보인다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 11 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(8)(%ED%91%9C%EB%B3%B8%EB%B6%84%ED%8F%AC)</link>
        <guid isPermaLink="true">http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(8)(%ED%91%9C%EB%B3%B8%EB%B6%84%ED%8F%AC)</guid>
        
        <category>K-digital training</category>
        
        <category>week2_day5</category>
        
        <category>인공지능 수학</category>
        
        
        <category>programmers</category>
        
      </item>
    
      <item>
        <title>인공지능수학(11)(엔트로피)</title>
        <description>&lt;h2 id=&quot;엔트로피&quot;&gt;엔트로피&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;자기정보(self-information) : $i(A)$
    &lt;ul&gt;
      &lt;li&gt;A : 사건&lt;/li&gt;
      &lt;li&gt;$ i(A) = {log_b({1\over {P(A)}})} = -log_bP(A)$&lt;/li&gt;
      &lt;li&gt;확률이 높은 사건:
        &lt;ul&gt;
          &lt;li&gt;정보가 많지 않음&lt;/li&gt;
          &lt;li&gt;예 : 도둑이 들었는데 개가 짖는 경우보다 도둑이 들었는데 개가 안 짖는 경우 더 많은 정보를 포함하고 있음&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;정보의 단위
        &lt;ul&gt;
          &lt;li&gt;b = 2 : bits&lt;/li&gt;
          &lt;li&gt;b = e : nats&lt;/li&gt;
          &lt;li&gt;b = 10 : hartley&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;특성
        &lt;ul&gt;
          &lt;li&gt;$ i(AB) ={log_b({1\over {P(A)P(B)}})} = {log_b({1\over {P(A)}})} + {log_b({1\over {P(B)}})} = i(A) + i(B)$&lt;/li&gt;
          &lt;li&gt;따라서, 두 사건이 동시에 있어났을 때, 자기정보는 각 자기정보의 합과 같다.&lt;/li&gt;
          &lt;li&gt;$ P(H) = {1\over8}, P(T) = {7\over8} $
            &lt;ul&gt;
              &lt;li&gt;$ i(H) = -log_bP(H) = -log_2{1 \over 8} = 3비트$&lt;/li&gt;
              &lt;li&gt;$ i(H) = -log_bP(T) = -log_2{7 \over 8} = 0.193비트$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;엔트로피(entropy)
    &lt;ul&gt;
      &lt;li&gt;자기 정보의 평균&lt;/li&gt;
      &lt;li&gt;$ H(X) = \sum_J P(A_j)i(A_j) = - \sum_jP(A_j)log_2 P(A_j) $&lt;/li&gt;
      &lt;li&gt;특성
        &lt;ul&gt;
          &lt;li&gt;$ 0 \le H(X) \le log_2K $ ( K : 사건의 수)
            &lt;ul&gt;
              &lt;li&gt;엔트로피 $H(X)$의 최대값은 $P(A_j)$가 모두 ${1\K}$인 경우이고 그때의 값이 $log_2K$이다.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;교차-엔트로피&quot;&gt;교차 엔트로피&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;확률분포 P와 Q
    &lt;ul&gt;
      &lt;li&gt;$ S = {A_j} $(사건 S)&lt;/li&gt;
      &lt;li&gt;$ P(A_j)$ : 확률분포 P에서 사건 $A_j$가 발생할 확률&lt;/li&gt;
      &lt;li&gt;$ Q(A_j)$ : 확률분포 Q에서 사건 $A_j$가 발생할 확률&lt;/li&gt;
      &lt;li&gt;$ i(A_j)$ : 확률분포 Q에서 사건 $A_j$의 자기정보
        &lt;ul&gt;
          &lt;li&gt;$ i(A_j) = -log_2Q(Aj)$&lt;/li&gt;
          &lt;li&gt;자기정보는 $A_j$를 표현하는 비트수&lt;/li&gt;
          &lt;li&gt;잘못된 확률분포 Q를 사용하게 되면, 실제 최적의 비트수를 사용하지 못하게 됨.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$H(P,Q)$
    &lt;ul&gt;
      &lt;li&gt;집합 S상에서 확률분포 P에 대한 확률분포 Q의 교차 엔트로피&lt;/li&gt;
      &lt;li&gt;확률분포 P에서 $i(A_j)$의 평균
        &lt;ul&gt;
          &lt;li&gt;$ H(P, Q) = \sum_j P(A_j)i(A_j) = - \sum_j P(A_j)log_2Q(A_j) = - \sum_{x \in X}P(X)log_2Q(x) $&lt;/li&gt;
          &lt;li&gt;이 값은 정확한 확률분포 P를 사용했을 때의 비트 수 보다 크게 됨
            &lt;ul&gt;
              &lt;li&gt;$ H(P,Q) = - \sum_{x \in X}P(X)log_2Q(x) \ge - \sum_{x \in X}P(X)log_2P(x) = H(P)$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;따라서 이 값은 P와 Q가 얼마나 비슷한지를 표현
            &lt;ul&gt;
              &lt;li&gt;같으면 $ H(P,Q) = H(P) $&lt;/li&gt;
              &lt;li&gt;다르면 $ H(P,Q) &amp;gt; H(P) $&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;분류 문제에서의 손실함수
    &lt;ul&gt;
      &lt;li&gt;분류문제
        &lt;ul&gt;
          &lt;li&gt;주어진 대상이 A인지 아닌지를 판단&lt;/li&gt;
          &lt;li&gt;주어진 대상이 A, B, C, … 중 어느 것인지를 판단&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;기계학습 에서는 주어진 대상이 각 그룹에 속할 확률을 제공
        &lt;ul&gt;
          &lt;li&gt;예) [0.8, 0.2]: A일 확률 0.8, 아닐확률 0.2&lt;/li&gt;
          &lt;li&gt;이 값이 정답인 [1.0 ,0.0] 과 얼마나 다른지 측정 필요&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;원하는 답 $P = [p_1, p_2, …, p_n], p_1 + p_2 + … + p_n = 1$&lt;/li&gt;
      &lt;li&gt;제시된 답 $Q = [q_1, q_2, …, q_n], q_1 + q_2 + … + q_n = 1$&lt;/li&gt;
      &lt;li&gt;제곱합
        &lt;ul&gt;
          &lt;li&gt;$\sum(p_i - q_i)^2$&lt;/li&gt;
          &lt;li&gt;확률이 다를수록 큰 값을 가짐&lt;/li&gt;
          &lt;li&gt;하지만 학습 속도 느림&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;교차 엔트로피 H(P, Q)
        &lt;ul&gt;
          &lt;li&gt;확률이 다를수록 큰 값을 가짐&lt;/li&gt;
          &lt;li&gt;학습 속도 빠름&lt;/li&gt;
          &lt;li&gt;분류 문제에서 주로 교차 엔트로피 사용&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;참고) 분류문제에서 원하는 답
        &lt;ul&gt;
          &lt;li&gt;$P = [p_1, p_2, …, p_n]$에서 $p_i$중 하나만 1이고, 나머지는 다 0임. 즉, 엔트로피는 0 (H(P) = 0)&lt;/li&gt;
          &lt;li&gt;$p_k = 1.0$ 이라고 하면, $q_k$의 값이 최대한 커지는 방향으로 학습 진행&lt;/li&gt;
          &lt;li&gt;예시)
            &lt;ul&gt;
              &lt;li&gt;S = ${A, B}$&lt;/li&gt;
              &lt;li&gt;P = $[1, 0]$&lt;/li&gt;
              &lt;li&gt;예측 $Q(x)$
                &lt;ul&gt;
                  &lt;li&gt;$[0.8, 0.2]: Q(A) = 0.8. Q(B) = 0.2$
                    &lt;ul&gt;
                      &lt;li&gt;$H(P, Q) = - \sum_{x \in X}log_2Q(x) = -1 \times log_20.8 = 0.3219$&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                  &lt;li&gt;$[0.5, 0.5]: Q(A) = 0.5. Q(B) = 0.5$
                    &lt;ul&gt;
                      &lt;li&gt;$H(P, Q) = - \sum_{x \in X}log_2Q(x) = -1 \times log_20.5 = 1$&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                  &lt;li&gt;$[0.8, 0.2]: Q(A) = 0.8. Q(B) = 0.2$
                    &lt;ul&gt;
                      &lt;li&gt;$H(P, Q) = - \sum_{x \in X}log_2Q(x) = -1 \times log_20.2 = 2.32$&lt;/li&gt;
                    &lt;/ul&gt;
                  &lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
              &lt;li&gt;H(P,Q)가 가장 작은 [0.8, 0.2]가 가장 정답에 가까움을 알 수 있다.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Fri, 11 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(11)(%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC)</link>
        <guid isPermaLink="true">http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(11)(%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC)</guid>
        
        <category>K-digital training</category>
        
        <category>week2_day5</category>
        
        <category>인공지능 수학</category>
        
        
        <category>programmers</category>
        
      </item>
    
      <item>
        <title>인공지능수학(10)(검정)</title>
        <description>&lt;h2 id=&quot;검정&quot;&gt;검정&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;가설 검정
    &lt;ul&gt;
      &lt;li&gt;예) 어떤 고등학교의 1학년 학생들의 평균키가 170.5cm로 알려져 있었다. 올해 새로 들어온 1학년 학생들 중 30명을 랜덤하게 선택하여 키를 잰 후 평균을 계산했더니 171.3cm이었다. 올해 신입생은 평균키가 170.5cm보다 더 크다고 할 수 있는가?&lt;/li&gt;
      &lt;li&gt;표본평균 $\bar X$가 $\mu_0$보다 얼마나 커야 모평균 $\mu$가 $\mu_0$보다 크다고 할 수 있을 것인가?
        &lt;ul&gt;
          &lt;li&gt;표본 평균은 표번의 선택에 의해 달라지는 점에 주의해야 한다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;귀무가설 $H_0 : \mu = \mu_0$&lt;/li&gt;
      &lt;li&gt;대립가설 $H_1 : \mu &amp;gt; \mu_0$&lt;/li&gt;
      &lt;li&gt;귀무가설(위 경우 모평균이 변하지 않았다는 가설)을 기각하기 위해서는 $\bar X$가 좀 큰 값이 나와야 한다.
        &lt;ul&gt;
          &lt;li&gt;귀무가설이 참이라고 가정할 때, 랜덤하게 선택한 표본에서 지금의 $\bar X$가 나올 확률을 계산할 필요&lt;/li&gt;
          &lt;li&gt;이 확률이 낮다면 귀무가설이 참이 아니라고 판단.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;확률이 낮다는 기준점이 필요
        &lt;ul&gt;
          &lt;li&gt;유의수준 $\alpha$도입 필요&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$P(\bar{X} \ge k) \le \alpha$가 되는 $k$를 찾아야함&lt;/li&gt;
      &lt;li&gt;표준 정규확률 변수로 변환 $\to$ 검정 통계량 이라고 함
        &lt;ul&gt;
          &lt;li&gt;$Z = { {\bar{X} - \mu}\over{s \over \sqrt n} } \sim N(0,1)$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;따라서, $\bar X$를 $Z$로 변환한 후 $Z$값이 $z_a$보다 큰지를 검토
        &lt;ul&gt;
          &lt;li&gt;크다면 귀무가설 기각&lt;/li&gt;
          &lt;li&gt;그렇지 않다면 귀무가설 채택&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;검정의 단계
        &lt;ul&gt;
          &lt;li&gt;$H_0, H_1$ 설정&lt;/li&gt;
          &lt;li&gt;유의수준 $\alpha$설정&lt;/li&gt;
          &lt;li&gt;검정통계량 계산&lt;/li&gt;
          &lt;li&gt;기각역 또는 임계값 계산&lt;/li&gt;
          &lt;li&gt;주어진 데이터로부터 유의성 판정&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;모평균의 검정
    &lt;ul&gt;
      &lt;li&gt;대립가설
        &lt;ul&gt;
          &lt;li&gt;문제에서 검정하고자 하는 것이 무엇인지 파악 필요
            &lt;ul&gt;
              &lt;li&gt;대립가설 $H_1$채택을 위한 통계적 증거 확보 필요&lt;/li&gt;
              &lt;li&gt;증거가 없으면 귀무가설 $H_0$채택&lt;/li&gt;
              &lt;li&gt;$H_1 : \mu \gt \mu_0$&lt;/li&gt;
              &lt;li&gt;$H_1 : \mu \lt \mu_0$&lt;/li&gt;
              &lt;li&gt;$H_1 : \mu \ne \mu_0$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;예시 : 어떤 농장에서 생산되는 계란의 평균 무게는 10.5그램으로 알려져 있다. 새로운 사료를 도입한 후에 생산된 계란 30개의 표본 평균을 계산했더니 11,4그램이 나왔다. 새로운 사료가 평균적으로 더 가벼운 계란을 생산한다고 할 수 있는가?
            &lt;ul&gt;
              &lt;li&gt;$H_0: \mu = 10.5$&lt;/li&gt;
              &lt;li&gt;$H_1: \mu \lt 10.5$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;예시 : 어떤 농장에서 자신들이 생산하는 계란의 평균 무게가 10.5그램이라고 홍보하고 있다. 이에 생산된 계란 30개의 표본 평균을 계산했더니 9.4그램이 나왔다. 이 농장의 광고가 맞다고 할 수 있나?
            &lt;ul&gt;
              &lt;li&gt;$H_0: \mu = 10.5$&lt;/li&gt;
              &lt;li&gt;$H_1: \mu \ne 10.5$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;검정 통계량
        &lt;ul&gt;
          &lt;li&gt;$n \ge 30$인 경우
            &lt;ul&gt;
              &lt;li&gt;중심극한 정리 사용&lt;/li&gt;
              &lt;li&gt;$Z = { {\bar{X} - \mu}\over{s \over \sqrt n} } \sim (0,1)$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;모집단이 정규 모집단이고, 모표준편차 $\sigma$가 주어진 경우
            &lt;ul&gt;
              &lt;li&gt;$Z = { {\bar{X} - \mu}\over{\sigma \over \sqrt n} }\sim N(0,1)$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;기각역
        &lt;ul&gt;
          &lt;li&gt;$H_0 : \mu = 10.5$&lt;/li&gt;
          &lt;li&gt;유의수준 : $\alpha$&lt;/li&gt;
          &lt;li&gt;기각역
            &lt;ul&gt;
              &lt;li&gt;$H_1 : \mu \gt 10.5 \to Z \gt z_\alpha $&lt;/li&gt;
              &lt;li&gt;$H_1 : \mu \lt 10.5 \to Z \lt -z_\alpha $&lt;/li&gt;
              &lt;li&gt;$H_1 : \mu \ne 10.5 \to \vert Z \vert \gt z_{\alpha \over 2} $&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;실제 예 : 어떤 농장에서 자신들이 생산하는 계란의 평균 무기가 10.5그램 이라고 홍보하고 있다. 이에 생산된 계란 30개의 표본을 뽑았더니 그 무게가 아래와 같다. 이 농장의 홍보가 맞는지 유의수준 5%로 검정하시오.
        &lt;ul&gt;
          &lt;li&gt;w = [10.7, 11.7, …]&lt;/li&gt;
          &lt;li&gt;$ H_0 : \mu = 10.5$&lt;/li&gt;
          &lt;li&gt;$ H_1 : \mu \ne 10.5$&lt;/li&gt;
          &lt;li&gt;$ \alpha = 0.05 $&lt;/li&gt;
          &lt;li&gt;$ \bar {X} = 10.43$&lt;/li&gt;
          &lt;li&gt;$ s = 1.11 $&lt;/li&gt;
          &lt;li&gt;$Z = { {\bar{X} - \mu}\over{s \over \sqrt n} } = { {10.43 - 10.5} \over {1.11 \over {\sqrt{30}}}} = -0.351$&lt;/li&gt;
          &lt;li&gt;$z_{\alpha \over 2} = z_{0.025} = 1.96 \gt \vert -0.351 \vert = \vert Z \vert$&lt;/li&gt;
          &lt;li&gt;따라서 귀무가설을 기각 할 수 없다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 11 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(10)(%EA%B2%80%EC%A0%95)</link>
        <guid isPermaLink="true">http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(10)(%EA%B2%80%EC%A0%95)</guid>
        
        <category>K-digital training</category>
        
        <category>week2_day5</category>
        
        <category>인공지능 수학</category>
        
        
        <category>programmers</category>
        
      </item>
    
      <item>
        <title>인공지능수학(7)(확률분포)</title>
        <description>&lt;h2 id=&quot;확률분포-관련-용어-정리&quot;&gt;확률분포 관련 용어 정리&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;확률 변수(random variable)
    &lt;ul&gt;
      &lt;li&gt;랜덤한 실험 결과에 의존하는 실수(표본 공간의 부분 집합에 대응하는 실수)&lt;/li&gt;
      &lt;li&gt;보통 X나 Y같은 대문자로 표시&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이산확률변수(discrete variable)
    &lt;ul&gt;
      &lt;li&gt;확률변수가 취할 수 있는 모든 수 값들을 하나씩 셀 수 있는 경우&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;연속 확률 변수(continuous random variable)
    &lt;ul&gt;
      &lt;li&gt;셀 수 없는 경우&lt;/li&gt;
      &lt;li&gt;예 : 어느 학교에서 랜덤하게 선택된 남학생의 키&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;확률 분포(Probability Distribution)
    &lt;ul&gt;
      &lt;li&gt;확률변수가 가질 수 있는 값에 대해 확률을 대응시켜 주는 관계&lt;/li&gt;
      &lt;li&gt;예 : 어떤 확률 변수 X가 가질 수 있는 값: 0, 1, 3, 8 일 때 각 값이 가질 수 있는 확률
        &lt;ul&gt;
          &lt;li&gt;$P(x=0) = 0.2$&lt;/li&gt;
          &lt;li&gt;$P(x=1) = 0.1$&lt;/li&gt;
          &lt;li&gt;$P(x=3) = 0.5$&lt;/li&gt;
          &lt;li&gt;$P(x=8) = 0.2$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이산확률변수의 평균
    &lt;ul&gt;
      &lt;li&gt;기대값(expected value)라고도 함.&lt;/li&gt;
      &lt;li&gt;$E(X) = \sum _x xP(X=x) = \sum_x xf(x)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이산확률변수의 분산
    &lt;ul&gt;
      &lt;li&gt;$(X-\mu)^2$의 평균&lt;/li&gt;
      &lt;li&gt;$\sigma ^ 2 = E[(X-\mu)^2] = \sum_x(x-\mu)^2P(X=x)$&lt;/li&gt;
      &lt;li&gt;$Var(X)$라고도 함&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이산확률변수의 표준편차
    &lt;ul&gt;
      &lt;li&gt;$\sqrt {Var(X)}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;확률변수 X의 분산(간편식)
    &lt;ul&gt;
      &lt;li&gt;$\sigma^2 = E(X^2) - (E(X))^2$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;결합확률 분포(Joint probability distribution)
    &lt;ul&gt;
      &lt;li&gt;두 개 이상의 확률 변수가 동시에 취하는 값들에 대해 확률을 대응시켜주는 관계&lt;/li&gt;
      &lt;li&gt;예) 확률변수 X : 한 학생이 가지는 휴대폰의 수, 확률변수 Y : 한 학생이 가지는 노트북의 수&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;공분산(Covariance)
    &lt;ul&gt;
      &lt;li&gt;예시 : 고등학교 1학년 학생들
        &lt;ul&gt;
          &lt;li&gt;확률변수 X : 키&lt;/li&gt;
          &lt;li&gt;확률변수 Y : 몸무게&lt;/li&gt;
          &lt;li&gt;확률변수 Z : 수학성적&lt;/li&gt;
          &lt;li&gt;$(X-\mu_x)(Y-\mu_y)$ : 양일 가능성 높음&lt;/li&gt;
          &lt;li&gt;$(X-\mu_x)(Z-\mu_z)$ : 양과 음이 될 가능성이 비슷할 것&lt;/li&gt;
          &lt;li&gt;$(X-\mu_x)(Y-\mu_y)$와 $(X-\mu_x)(Z-\mu_z)$
            &lt;ul&gt;
              &lt;li&gt;각가이 확률변수의 역할을 할 수 있음&lt;/li&gt;
              &lt;li&gt;따라서 평균과 분산을 구할 수 있음&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$Cov(X,Y) = E[(X-\mu_x)(Y-\mu_y)]$&lt;/li&gt;
      &lt;li&gt;$E(XY) - \mu_x\mu_y = E[XY] - E[X]E[Y]$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;상관계수(correlation coefficient)
    &lt;ul&gt;
      &lt;li&gt;공분산은 각 확률 변수의 절대적인 크기에 영향을 받음(단위에 의한 영향을 없앨 필요)&lt;/li&gt;
      &lt;li&gt;$\rho = Corr(X,Y) = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;몇-가지-확률분포&quot;&gt;몇 가지 확률분포&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;이항분포(bionomial distribution)
    &lt;ul&gt;
      &lt;li&gt;베르누이 시행(Bernoulli trial)
        &lt;ul&gt;
          &lt;li&gt;정확하게 2개의 결과만을 가지는 실험(예: 동정던지기)&lt;/li&gt;
          &lt;li&gt;보통 성공과 실패로 결과를 구분&lt;/li&gt;
          &lt;li&gt;성공의 확률 : p&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;확률변수 X
        &lt;ul&gt;
          &lt;li&gt;n번의 베르누이 시행에서 성공의 횟수&lt;/li&gt;
          &lt;li&gt;이향확률변수라고 함&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;이항분포는 이항확률변수의 확률분포&lt;/li&gt;
      &lt;li&gt;$f(x) = P[X = x] = \begin{pmatrix}n \cr x \end{pmatrix}p^x(1-p)^{n-x}$&lt;/li&gt;
      &lt;li&gt;예시) 어떤 랜덤박스의 뽑기 성공 확률이 0.2이다 3개를 뽑았을 때, 적어도 하나 이상의 성공이 발생할 확률은?&lt;/li&gt;
      &lt;li&gt;$P[X \ge 1] = 1 - P[X=0] = 1- \begin{pmatrix}3 \cr 0 \end{pmatrix}0.2^0(0.8)^{3-0} = 1 - 0.512 = 0.488$&lt;/li&gt;
      &lt;li&gt;python으로의 구현
        &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# binom.cdf는 입력값 0 보다 작거나 같은 값들의 확률을 구해줌. n은 시행회수 p는 확률
&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;이항분포의 평균
        &lt;ul&gt;
          &lt;li&gt;$E(X) = np$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;이항분포의 분산
        &lt;ul&gt;
          &lt;li&gt;$Var(X) = np(1-p)$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;표준편차
        &lt;ul&gt;
          &lt;li&gt;$SD(X) = \sqrt{np(1-P})$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;#평균은 0.6, 분산은 0.48
&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.48&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;연속확률 변수의 확률분포
    &lt;ul&gt;
      &lt;li&gt;확률밀도함수(probability density function)를 써서 표현함&lt;/li&gt;
      &lt;li&gt;$P[a \le x \le b] = \int_a^b f(x)dx$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;정규분포
    &lt;ul&gt;
      &lt;li&gt;$f(x) = {1 \over {\sqrt{2 \pi}\sigma}} e^{-{1 \over 2}({\frac{x - \mu}{\sigma})^2}} $&lt;/li&gt;
      &lt;li&gt;$x = \mu$일 때, 가장 높은 값을 가지는 좌우 대칭의 그래프 모양을 가진다.&lt;/li&gt;
      &lt;li&gt;표현 : $X \sim N(\mu, \sigma^2)$&lt;/li&gt;
      &lt;li&gt;표준정규확률변수(standart normaal random variable)
        &lt;ul&gt;
          &lt;li&gt;$Z = \frac{X - \mu}{\sigma}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;표준정규분포(standart normal distribution)
        &lt;ul&gt;
          &lt;li&gt;$Z \sim N(0, 1)$&lt;/li&gt;
          &lt;li&gt;표준 정규분포표
            &lt;ul&gt;
              &lt;li&gt;$P[X \le z]$&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;예시: $X \sim N(4, 3)$ 에서 $P[X \le 4] = ??$
            &lt;ul&gt;
              &lt;li&gt;$P[ \frac{X - \mu}{\sigma} \le \frac{4 - \mu}{\sigma} ] = P[Z \le \frac {4 - 4}{3}] = P[Z \le 0] = 0.5$
                &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;                &lt;/div&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;포아송 분포(Poisson distribution)
    &lt;ul&gt;
      &lt;li&gt;일정한 시간단위 또는 공간 단위에서 발생하는 이벤트의 수의 확률분포
        &lt;ul&gt;
          &lt;li&gt;하루동안 어떤 웹사이트를 방문하는 방문자으 ㅣ수&lt;/li&gt;
          &lt;li&gt;어떤 미용실에 한 시간동안 방문하는 손님의 수&lt;/li&gt;
          &lt;li&gt;어떤 전기선 100미터당 발생하는 결함의 수&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;확률분포함수(확률질량함수)
        &lt;ul&gt;
          &lt;li&gt;$P[X = x] = f(x) = \lambda^x \frac{e^{-\lambda}}{x!}, x = 0,1,2,…$&lt;/li&gt;
          &lt;li&gt;평균: $\lambda$&lt;/li&gt;
          &lt;li&gt;분산: $\lambda$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;예시: 어느 웹사이트에 시간당 접속자 수는 평균이 3$(\lambda = 3)$인 포아송 분포를 따른다고 한다. 앞으로 1시간 동안 접속자 수가 2명 이하일 확률은?
        &lt;ul&gt;
          &lt;li&gt;$P[X \le 2] = P[X = 0] + p[X = 1] +P[X = 2] = 3^0 \frac{e^{-3}}{0!} + 3^1 \frac{e^{-3}}{1!} + 3^2 \frac{e^{-3}}{2!}$ 
  $= 0.42319$
            &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;poisson&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;mf&quot;&gt;0.42319008112684364&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;지수분포(exponential distribution)
    &lt;ul&gt;
      &lt;li&gt;포아송 분포에 의해 어떤 사건이 발생할 때, 어느 한 시점으로부터 이 사건이 발생할 때 까지 걸리는 시간에 대한 확률 분포&lt;/li&gt;
      &lt;li&gt;확률밀도 함수
        &lt;ul&gt;
          &lt;li&gt;$f(t) = \lambda e^{-\lambda t}$&lt;/li&gt;
          &lt;li&gt;$\lambda$ : 포아송분포의 평균&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;평균
        &lt;ul&gt;
          &lt;li&gt;$E(T) = {1 \over \lambda}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;분산
        &lt;ul&gt;
          &lt;li&gt;$Var(T) = {1 \over \lambda^2}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;예시: 어느 웹사이트에 시간당 접속자 수는 $\lambda = 3$인 포아송 분포를 따른다고 한다. 지금부터 시작하여 첫번째 접속자가 30분 이내에 올 확률은($P[T\le 0.5])$?
        &lt;ul&gt;
          &lt;li&gt;$P[T\le 0.5]) = \int_0^{0.5}\lambda e^{-\lambda t}dt = \int_0^{0.5}3 e^{-3 t}dt = 0.7769$
            &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;# 0.5는 시간 scale에는 표준편차를 넣어줌
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;            &lt;/div&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 10 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(7)(%ED%99%95%EB%A5%A0%EB%B6%84%ED%8F%AC)</link>
        <guid isPermaLink="true">http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(7)(%ED%99%95%EB%A5%A0%EB%B6%84%ED%8F%AC)</guid>
        
        <category>K-digital training</category>
        
        <category>week2_day4</category>
        
        <category>인공지능 수학</category>
        
        
        <category>programmers</category>
        
      </item>
    
      <item>
        <title>인공지능수학(6)(확률) </title>
        <description>&lt;h2 id=&quot;확률-개념-정의&quot;&gt;확률 개념 정의&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;고전적 정의
    &lt;ul&gt;
      &lt;li&gt;표본공간(sample space) : 모든 가능한 실험결과들의 집합 (예: 주사위의 숫자의 표본공간은 {1,2,3,4,5,6})&lt;/li&gt;
      &lt;li&gt;사건 : 관심있는 실험 결과들의 집합, 표본 공간의 부분집합 (예: 주사위의 숫자 중 짝수인 경우 {2,4,6})&lt;/li&gt;
      &lt;li&gt;어떤 사건이 일어날 확률 : 표본공간의 모든 원소가 일어날 확률이 같은 경우에 (사건의 원소의 수 / 표본공간의 원소의 수)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;조합(combination)
    &lt;ul&gt;
      &lt;li&gt;어떤 집합에서 순서에 상관없이 뽑은 원소의 집합&lt;/li&gt;
      &lt;li&gt;$_nC_r = \begin{pmatrix} n \cr r \end{pmatrix} = \frac{n!}{r!(n-r)!}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;덧셈 법칙(Addition Law)
    &lt;ul&gt;
      &lt;li&gt;사건 A = 주사위의 수가 짝수인 사건
        &lt;ul&gt;
          &lt;li&gt;$P(A) = {1 \over 2}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;사건 B = 주사위의 숫자가 4이상인 사건
        &lt;ul&gt;
          &lt;li&gt;$P(B) = {1 \over 2}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;사건 A나 사건 B가 일어날 확률
        &lt;ul&gt;
          &lt;li&gt;$A \cup B$ = {2, 4, 5, 6}&lt;/li&gt;
          &lt;li&gt;$P(A \cup B) = {2 \over 3}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;사건 A와 사건 B가 동시에 일어날 확률
        &lt;ul&gt;
          &lt;li&gt;$A \cap B$ = {4, 6}&lt;/li&gt;
          &lt;li&gt;$P(A \cap B) = {1 \over 3}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$P(A \cup B) = P(A) + P(B) - P(A \cap B)$
        &lt;ul&gt;
          &lt;li&gt;$ {2 \over 3} = {1 \over 2} + {1 \over 2} - {1 \over 3}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;서로 배반(Mutually Exclusive)
    &lt;ul&gt;
      &lt;li&gt;두 사건의 교집합이 공집합인 경우&lt;/li&gt;
      &lt;li&gt;$P(A \cap B) = 0$&lt;/li&gt;
      &lt;li&gt;$P(A \cup B) = P(A) + P(B)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;조건부 확률(Conditional Probability)
    &lt;ul&gt;
      &lt;li&gt;어떤 사건 A가 일어났을 때, 다른 사건 B가 일어날 확률&lt;/li&gt;
      &lt;li&gt;$P(B | A) = \frac{P(A \cap B)}{P(A)}$&lt;/li&gt;
      &lt;li&gt;예 : 주사위를 던져서 4이상이 나왔을 때, 그 수가 짝수일 확률은?
        &lt;ul&gt;
          &lt;li&gt;$P(B | A) = \frac{P(A \cap B)}{P(A)} = \frac{1 \over 3}{1 \over 2} = {2 \over 3}$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;곱셈 법칙
    &lt;ul&gt;
      &lt;li&gt;$P(A \cap B) = P(B|A)P(A)$(조건부 확률의 수식에 의해서)&lt;/li&gt;
      &lt;li&gt;만약 A사건과 B사건이 독립인 경우 $P(B|A) = P(B)$&lt;/li&gt;
      &lt;li&gt;이때, $P(A \cap B) = P(B)P(A)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;여사건
    &lt;ul&gt;
      &lt;li&gt;사건 A의 여사건 : 사건 A가 일어나지 않을 사건&lt;/li&gt;
      &lt;li&gt;$A^c$&lt;/li&gt;
      &lt;li&gt;$P(A \cup B) = P(A) + P(A^c) = 1$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;확률의 분할법칙
    &lt;ul&gt;
      &lt;li&gt;$P(B) = P(A \cap B) + P(A^c \cap B)$&lt;/li&gt;
      &lt;li&gt;$= P(B | A)P(A) + P(B|A^c)P(A^C)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;베이즈 정리
    &lt;ul&gt;
      &lt;li&gt;처음의 확률(사전확률: Prior probability)&lt;/li&gt;
      &lt;li&gt;수정된 확률(사후확률: Posterior probability)&lt;/li&gt;
      &lt;li&gt;$P(A|B) = \frac {P(B \cap A)}{P(B)} = \frac {P(B|A)P(A)}{P(B|A)P(A) + P(b|A^c)P(A^c)}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 10 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(6)(%ED%99%95%EB%A5%A0)</link>
        <guid isPermaLink="true">http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(6)(%ED%99%95%EB%A5%A0)</guid>
        
        <category>K-digital training</category>
        
        <category>week2_day4</category>
        
        <category>인공지능 수학</category>
        
        
        <category>programmers</category>
        
      </item>
    
      <item>
        <title>인공지능수학(5)(통계학 기본개념)</title>
        <description>&lt;h2 id=&quot;통계학-개념-정의&quot;&gt;통계학 개념 정의&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;모집단(population):
    &lt;ul&gt;
      &lt;li&gt;어떤 질문이나 실험을 위해 관심의 대상이 되는 개체나 사건의 집합&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;모수(parameter):
    &lt;ul&gt;
      &lt;li&gt;모집단의 수치적인 특성&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;표본(sample):
    &lt;ul&gt;
      &lt;li&gt;모집단에서 선택된 개체나 사건의 집합&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;도수(frequency):
    &lt;ul&gt;
      &lt;li&gt;어떤 사건이 실험이나 관찰로부터 발생한 횟수&lt;/li&gt;
      &lt;li&gt;표현 방법: 도수분포표(frequency distribution table), 막대 그래프 (bar graph), 히스토그램(Histogram)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;상대도수:
    &lt;ul&gt;
      &lt;li&gt;도수를 전체 원소의 수로 나눈 수치&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;python으로-구현하는-통계&quot;&gt;python으로 구현하는 통계&lt;/h2&gt;

&lt;h3 id=&quot;평균mean&quot;&gt;평균(mean)&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;statistics&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;31&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;statistic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;40.132&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;중앙값median&quot;&gt;중앙값(Median)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;중앙값은 주어진 자료를 높은 쪽 절반과 낮은 쪽 절반으로 나누는 값을 의미한다.&lt;/li&gt;
  &lt;li&gt;자료의 수 : n
    &lt;ul&gt;
      &lt;li&gt;n이 홀수 : $(n+1) \over 2$번째 자료값&lt;/li&gt;
      &lt;li&gt;n이 짝수 : $n \over 2$번째와 ${n \over 2} + 1$번째 자료값의 평균&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;평균의 경우는 극단적인 값들의 영향을 크게 받지만, 중앙값은 그렇지 않다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;statistics&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;median&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;분산variance&quot;&gt;분산(Variance)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;편차의 제곱의 합을 자료의 수로 나눈 값
    &lt;ul&gt;
      &lt;li&gt;편차 : 값과 평균의 차이&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;자료가 모집단일 경우 : 모분산
    &lt;ul&gt;
      &lt;li&gt;$\sigma ^ 2= {1 \over N} \sum_1^N(x_i - \mu)^2$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;자료가 표본일 경우 : 표본분산
    &lt;ul&gt;
      &lt;li&gt;$s ^ 2= {1 \over n-1} \sum_1^n(x_i - \bar x)^2$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;statistics&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.stats&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;표준편자standard-deviation&quot;&gt;표준편자(Standard Deviation)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;모표준편차(population standard deviation) : 모분산의 제곱근&lt;/li&gt;
  &lt;li&gt;표본표준편차(sample standart deviation) : 표본분산의 제곱근&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;statistics&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stdev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;모분산과 모표준편차의 경우 statistics 모듈을 이용하면 다음과 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;statistics&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#모분산
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pvariance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#모표준편차
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pstdev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;numpy를 사용했을 때 모분산과 모표준편차 표본분산과 표본표준편차&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#모분산
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#모표준편차
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#표본분산
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddof&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#표본표준편차
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddof&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;ddof = Delta Degrees of Freedom(자유도)&lt;/p&gt;

&lt;h3 id=&quot;범위rnage&quot;&gt;범위(Rnage)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;자료를 정렬하였을 때 가장 큰 값과 가장 작은 값의 차이
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;사분위수quartile&quot;&gt;사분위수(Quartile)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;전체 자료를 정렬했을 때, 1/4. 1/2, 3/4 위치에 있는 숫자
    &lt;ul&gt;
      &lt;li&gt;Q1 : 제 1사분위수&lt;/li&gt;
      &lt;li&gt;Q3 : 제 3사분위수&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;사분위 범위(IQR, InterQuartile range): Q3 - Q1&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#Q1
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;54.25&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#중앙값
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;76.0&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#Q3
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;84.75&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 60%에 해당되는 수
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;78.8&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;z-score&quot;&gt;z-score&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;어떤 값이 평균으로부터 몇 표준편차 만큼 떨어져 있는지를 의미하는 값
    &lt;ul&gt;
      &lt;li&gt;모집단의 경우 : $z = \frac {x-\mu}{\sigma}$&lt;/li&gt;
      &lt;li&gt;표본의 경우 : $z = \frac {x-\bar x}{s}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.stats&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zscore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.12312345&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.1234591&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#표본에 대한 z-score는 이렇게해야함
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zscore&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ddof&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.12312345&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.1234591&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Wed, 09 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(5)(%ED%86%B5%EA%B3%84%ED%95%99-%EA%B8%B0%EB%B3%B8%EA%B0%9C%EB%85%90)</link>
        <guid isPermaLink="true">http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(5)(%ED%86%B5%EA%B3%84%ED%95%99-%EA%B8%B0%EB%B3%B8%EA%B0%9C%EB%85%90)</guid>
        
        <category>K-digital training</category>
        
        <category>week2_day3</category>
        
        <category>인공지능 수학</category>
        
        
        <category>programmers</category>
        
      </item>
    
      <item>
        <title>인공지능수학(4)(벡터공간과 최소제곱법)</title>
        <description>&lt;h2 id=&quot;최소제곱법의-의미&quot;&gt;최소제곱법의 의미&lt;/h2&gt;
&lt;p&gt;선형 시스템 $Ax = b $에 대한 해가 없음에도 불구하고, 가능한 최선의 결론을 도출해 내기 위함. 행렬 $A$가 정의하는 열공간에서 목표 b와 가장 가까운 지점은 $b$를 열공간에 투영(projection)한 지점이다. 즉, 달성가능한 최선의 목표 $proj_w^b$를 생각할 수 있다.($w$는 $A$의 column spacd) &lt;br /&gt;
최소제곱법은 선형 시스팀 $Ax = b$에 대한 해 $x$가 없음에도 불구하고, 할 수 있는 최선의 대안 $\bar x$를 내놓는 기법이다. 최소 제곱법은 원래의 선형 시스템 $Ax = b$가 아닌 다음의 선형시스템을 해결한다. &lt;br /&gt;
$A\bar x = \bar b(단, \bar b = proj_wb)$ &lt;br /&gt;
이 방법은 목표 $b$와 달성가능한 목표 $\bar b$의 차이를 나타내는 벡터 $(b - \bar b)$의 제곱길이를 최소화시키는 의미를 가지기 때문에 최소제곱법(least squares method)이라 불리운다.&lt;/p&gt;

&lt;h3 id=&quot;최소제곱법의-해를-구하는-방법&quot;&gt;최소제곱법의 해를 구하는 방법&lt;/h3&gt;
&lt;p&gt;주어진 선형 시스템의 양변에 전치행렬 $A^T$를 곱하면 최소제곱법의 해를 구할 수 있다. &lt;br /&gt;
$Ax = b$ &lt;br /&gt;
$\to A^T A \bar x = A^T b$ &lt;br /&gt;
$\to \bar x = (A^TA)^{-1}A^T b$&lt;/p&gt;

&lt;h5 id=&quot;최소제곱법의-예시선형회귀-linear-regression&quot;&gt;최소제곱법의 예시(선형회귀: Linear Regression)&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;선형시스템 구성: 직선이 각 정점$(-3,-1), (-1,-1), (1,3), (3,3)$을 모두 지나간다고 가정하고 선형시스템 $Ax = b$를  구성하면 다음과 같다.($m$이 기울기, $b$가 $y$절편) &lt;br /&gt;
$\begin{bmatrix} -3 &amp;amp; 1 \cr -1 &amp;amp; 1 \cr 1 &amp;amp; 1 \cr 3 &amp;amp; 1 \end{bmatrix}
\begin{bmatrix} m \cr b \end{bmatrix} = 
\begin{bmatrix} -1 \cr -1 \cr 3 \cr 3 \cr \end{bmatrix}
$&lt;/li&gt;
  &lt;li&gt;최소 제곱법 적용 :
$A^T A \bar x = A^T b$를 생각하고, $\bar x = \begin{bmatrix} \bar m \cr \bar b \end{bmatrix}$를 구한다. &lt;br /&gt;
$A^T = \begin{bmatrix} -3 &amp;amp; -1 &amp;amp; 1 &amp;amp; 3 \cr 1 &amp;amp; 1 &amp;amp; 1   \end{bmatrix}$이므로, &lt;br /&gt;
$\begin{bmatrix} -3 &amp;amp; -1 &amp;amp; 1 &amp;amp; 3 \cr 1 &amp;amp; 1 &amp;amp; 1   \end{bmatrix} \begin{bmatrix} -3 &amp;amp; 1 \cr -1 &amp;amp; 1 \cr 1 &amp;amp; 1 \cr 3 &amp;amp; 1 \end{bmatrix}
\begin{bmatrix} m \cr b \end{bmatrix} = 
\begin{bmatrix} -3 &amp;amp; -1 &amp;amp; 1 &amp;amp; 3 \cr 1 &amp;amp; 1 &amp;amp; 1   \end{bmatrix} \begin{bmatrix} -1 \cr -1 \cr 3 \cr 3 \cr \end{bmatrix}
$ &lt;br /&gt;
다음의 해를 구한다.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 09 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(4)(%EB%B2%A1%ED%84%B0%EA%B3%B5%EA%B0%84%EA%B3%BC-%EC%B5%9C%EC%86%8C%EC%A0%9C%EA%B3%B1%EB%B2%95)</link>
        <guid isPermaLink="true">http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(4)(%EB%B2%A1%ED%84%B0%EA%B3%B5%EA%B0%84%EA%B3%BC-%EC%B5%9C%EC%86%8C%EC%A0%9C%EA%B3%B1%EB%B2%95)</guid>
        
        <category>K-digital training</category>
        
        <category>week2_day3</category>
        
        <category>인공지능 수학</category>
        
        
        <category>programmers</category>
        
      </item>
    
      <item>
        <title>인공지능수학(3)(svd, pca)</title>
        <description>&lt;h2 id=&quot;특이값-분해svd-singular-value-decomposition&quot;&gt;특이값 분해(SVD, Singular Value Decomposition)&lt;/h2&gt;
&lt;p&gt;$LU$ 분해와 $QR$분해는 $n \times n$ 정방행렬(square matrix)에 대한 행렬분해인 반면, 특이값 분해는 일반적인 $m \times n$ 행렬에 관한 행렬 분해이다. 특이값 분해는 직교분할, 확대축소, 차원변환 등과 관련이 있다.&lt;/p&gt;

&lt;p&gt;특이값 분해는 주어진 행렬을 아래의 형태를 가지는 세 행렬의 곱으로 나누는 행렬분해 이다. &lt;br /&gt;
$A_{m \times n} = B_{m \times m} D_{m \times n} V_{n \times n}^T$&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$U$ : $m$차원 회전행렬(정규직교행렬), 입력 차원인 $R^m$공간에서의 회전&lt;/li&gt;
  &lt;li&gt;$D$ : $n$차원 확대축소(확대축소 크기에 따른 정렬 형태), 입력 차원인 $R^n$공간에 대해 축방향으로의 확대축소한 후, $R^n \to R^m$으로 차원 변환&lt;/li&gt;
  &lt;li&gt;$V$ : $n$차원 회전행렬(정규직교행렬), 입력차원인 $R^n$공간에서의 회전&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;주성분-분석pca-principal-component-analysis&quot;&gt;주성분 분석(PCA, Principal Component Analysis)&lt;/h2&gt;
&lt;p&gt;주성분 분석(PCA)는 데이터의 공분산행렬(convariance matrix)에 대한 고유값 분해에 기반을 둔 직교분해이다. $K$개의 $n$차원 데이터 $[x_i]_{i=1}^K$가 있을 때, 데이터의 중심 $m$과 공분산행렬 $C$는 다음과 같이 구한다. &lt;br /&gt;
$m = {1 \over K}$ $\sum_1^n x_i$ &lt;br /&gt;
   $C = {1 \over K}$ $\sum_1^K (x_i - m)(x_i - m)^T$&lt;/p&gt;

&lt;p&gt;공분산행렬에 대해 주성분분석$(PCA)$는 아래와 같다.
$C_{n \times n} = W_{n \times n} D_{n \times n} W_{n \times n}^T$&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$W$ : $n$차원 회전행렬(정규직교행렬), 입력 차원인 $R^m$공간에서의 회전&lt;/li&gt;
  &lt;li&gt;$D$ : $n$차원 확대축소(확대축소 크기에 따른 정렬 형태), 입력 차원인 $R^n$공간에 대해 축방향으로의 확대축소한 후, $R^n \to R^m$으로 차원 변환&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 09 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(3)(SVD,-PCA)</link>
        <guid isPermaLink="true">http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(3)(SVD,-PCA)</guid>
        
        <category>K-digital training</category>
        
        <category>week2_day3</category>
        
        <category>인공지능 수학</category>
        
        
        <category>programmers</category>
        
      </item>
    
      <item>
        <title>인공지능수학(2)(벡터와 직교분해)</title>
        <description>&lt;h2 id=&quot;벡터의-투영projection&quot;&gt;벡터의 투영(projection)&lt;/h2&gt;
&lt;p&gt;두 벡터 $u, a$가 있을 때, 벡터 $u$를 $a$ 위에 투영한 벡터를 $proj_au$라하고 다음과 같이 구한다.
$proj_au = (u \cdot \frac{1}{\Vert a \Vert}\Vert a \Vert) (\frac{1}{\Vert a \Vert}\Vert a \Vert) = (\frac{u \cdot a}{\Vert a \Vert^2})a$ &lt;br /&gt;
위의 식에서 $(u \cdot \frac{1}{\Vert a \Vert}\Vert a \Vert)$는 투영한 벡터의 길이를 나타내고 $(\frac{1}{\Vert a \Vert}\Vert a \Vert)$는 방향을 나타내고 이를 곱한 결과값은 다시 (기저 a에 대한 좌표값)a 로 나타낼 수 있다. &lt;br /&gt;
$(u \cdot \frac{1}{\Vert a \Vert}\Vert a \Vert)$을 얻어낸 과정은 다음과 같다. &lt;br /&gt;
$ \Vert u \Vert \Vert a \Vert cos\theta = u \cdot a
$
이고(내적의 정의) 이중 투영한 벡터의 길이인 $\Vert u \Vert cos \theta = u \cdot \frac{1}{\Vert a \Vert}\Vert a \Vert$ 이 된다. &lt;br /&gt;
벡터 $u$를 $a$위에 투영하고 남은 보완벡터(complement vector) 는 $u - proj_au$이다.&lt;/p&gt;

&lt;h2 id=&quot;직교행렬orthogonal-matrix&quot;&gt;직교행렬(orthogonal matrix)&lt;/h2&gt;
&lt;p&gt;주어진 행렬의 모든 열벡터가 서로 직교한다면, 이 행렬을 직교행렬 이라고 한다. 직교행렬은 직교 좌표계를 의미한다. &lt;br /&gt;
$\begin{bmatrix} 1 &amp;amp; 4 \cr -2 &amp;amp; 2 \end{bmatrix}  \begin{bmatrix} 2 &amp;amp; 2 &amp;amp; -4 \cr 2 &amp;amp; 1 &amp;amp; 7 \cr 6 &amp;amp; -1 &amp;amp; -1 \end{bmatrix}$ &lt;br /&gt;
위의 두 행렬은 모두 직교 행렬이다. 첫번째 행렬의 두 열벡터 $(1, -2), (4, 2)$ 는 직교한다(내적이 0). 두번째 행렬에 세 열벡터 $(2, 2, 6), (2, 1, 1), (-4, 7, -1)$도 각각 직교한다. 직교행렬중에 모든 열벡터의 크기가 1인 행렬을 정규직교행렬(prthonormal matrix)이라고 한다. 정규직교행렬은 정규직교좌표계를 의미한다.&lt;/p&gt;

&lt;h3 id=&quot;직교행렬의-응용&quot;&gt;직교행렬의 응용&lt;/h3&gt;
&lt;p&gt;선형시스템 $Ax = b$에서 행렬 $A$가 직교행렬이면, 해 $x$는 &lt;strong&gt;역행렬 $A^{-1}$의 계산 없이&lt;/strong&gt; 다음과 같이 구할 수 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$x$의 i-번째 요소는 투영으로 계산할 수 있다. 즉, 벡터 $b$를 행렬 $A$의 각 열벡터 $a_i$에 투영한 연산 $proj_{a_i} b$로부터 $x_i = \frac{b \cdot a_i}{\Vert a_i \Vert ^2}$&lt;/li&gt;
  &lt;li&gt;$x$의 i-번째 요소와 j-번째 요소의 계산은 독립적이다. 즉, x의 계산은 병렬처리 가능하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;예제--직교행렬-기반-선형시스템&quot;&gt;예제 : 직교행렬 기반 선형시스템&lt;/h5&gt;
&lt;p&gt;$\begin{bmatrix} 1 &amp;amp; 4 \cr -2 &amp;amp; 2 \end{bmatrix}  \begin{bmatrix} x_1 \cr x_2 \end{bmatrix} = \begin{bmatrix} 6 \cr -2 \end{bmatrix}$ 에서 $x_i = \frac{b \cdot a_i}{\Vert a_i \Vert ^2}$임을 이용해 $x_1$과 $x_2$를 다음과 같이 구할 수 있다.  &lt;br /&gt;
$x_1 = \frac{\begin{bmatrix} 6 \cr -2 \end{bmatrix} \cdot \begin{bmatrix} 1 \cr -2 \end{bmatrix}}{1^2 + (-2)^2} = 2$ &lt;br /&gt;
$x_2 = \frac{\begin{bmatrix} 6 \cr -2 \end{bmatrix} \cdot \begin{bmatrix} 4 \cr 2 \end{bmatrix}}{4^2 + 2^2} = 1$&lt;/p&gt;

&lt;h5 id=&quot;정규직교행렬의-경우&quot;&gt;정규직교행렬의 경우&lt;/h5&gt;
&lt;p&gt;정규 직교 행렬의 경우에 각각의 열벡터의 크기가 1이므로 위에서 단순하게 &lt;br /&gt;
$x_i = b \cdot a_i$로 구할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;qr분해&quot;&gt;QR분해&lt;/h2&gt;
&lt;p&gt;QR 분해는 주어진 행렬을 다음의 두 형태의 행렬 곱으로 나누는 행렬분해를 의미한다.
$A = QR$&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Q : orthonormal matrix(정규직교행렬)&lt;/li&gt;
  &lt;li&gt;U : upper triangular matrix(상삼각행렬)
    &lt;ul&gt;
      &lt;li&gt;상삼각행렬의 예시 : $\begin{bmatrix} * &amp;amp; * &amp;amp; * \cr 0 &amp;amp; * &amp;amp; * \cr 0 &amp;amp; 0 &amp;amp; * \end{bmatrix}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;qr분해의-활용&quot;&gt;QR분해의 활용&lt;/h3&gt;
&lt;p&gt;QR분야는 다음의 이유로 활용된다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;빠른 계산 : 선형시스템 $Ax = b$의 해를 구할 때, 정규직교행렬(orthonormal matrix) $Q$를 이용한 계산 부분은 병렬처리로 빨리 계한할 수 있습니다. 그러나 $R$을 이용한 계싼 부분은 병렬처리 할 수 없습니다.&lt;/li&gt;
  &lt;li&gt;$b$가 자주 업데이트 되는 경우 : 선형시스템 $Ax = b$에서 행렬 A는 고정되어 있고 $b$가 자주 변하는 문제가 종종 있다. 이런 경우, 행렬 $A$를 미리 $QR$로 분해해 둔다면, $b$가 업데이트 될 때마다 선형시스템의 해 $x$를 실시간으로 구할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;qr분해-vs-lu-분해&quot;&gt;QR분해 vs LU 분해&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;LU 분해의 경우, 선형시스템을 풀 때 병렬처리 할 수 없습니다.&lt;/li&gt;
  &lt;li&gt;QR분해의 경우, Q 행렬이 꽉찬 구조를 가진 행렬이므로 메모리 사용량이 많습니다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 09 Dec 2020 00:00:00 +0900</pubDate>
        <link>http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(2)(%EB%B2%A1%ED%84%B0%EC%99%80-%EC%A7%81%EA%B5%90%EB%B6%84%ED%95%B4)</link>
        <guid isPermaLink="true">http://localhost:4000http://localhost:4000/programmers/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%88%98%ED%95%99(2)(%EB%B2%A1%ED%84%B0%EC%99%80-%EC%A7%81%EA%B5%90%EB%B6%84%ED%95%B4)</guid>
        
        <category>K-digital training</category>
        
        <category>week2_day3</category>
        
        <category>인공지능 수학</category>
        
        
        <category>programmers</category>
        
      </item>
    
  </channel>
</rss>