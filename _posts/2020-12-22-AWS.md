---
category: programmers
tags: [K-digital training, week4_day3, aws]
use_math: true
---
 
## 클라우드 서비스 제공 모델

1. On-Premise: 사용자가 모든것을 관리하는 모델
2. IaaS : Infra적인 측면은 Cloud에서 사용, 나머지는 직접 관리
3. PasS : Platform까지 Cloud가 제공, 나머지는 직접 관리
4. SaaS : SoftWare까지 모두 제공받는 모델

## Inference를 위한 model handler 개발
### skeleton code
```python
class MLModeHandler(BaseHandler):
    def __init__(self):
        pass
    def initialize(self, **kwargs):
        pass
    def preprocess(self, data):
        pass
    def inference(self, data):
        pass
    def postprocess(self, data):
        pass
    def handle(self, data):
        pass
```

### handle()
- 요청 정보를 받아 적절한 응답을 반환
1. 정의된 양식으로 데이터가 입력됐는지 확인
2. 입력 값에 대한 전처리 및 모델에 입력하기 위한 형태로 변환
3. 모델 추론
4. 모델 반환값의 후처리 작업
5. 결과 반환

```python
    def handle(self, data):
        model_input = self.preprocess(data)
        model_output = self.inference(model_input)
        return self.postprocess(model_output)
```

### initialize()
- 데이터 처리나 모델, configuration 등 초기화
1. Configuration 등 초기화
2. (Optional) 신경망을 구성하고 초기화
3. 사전 학습한 모델이나 전처리기 불러오기 (De-serialization)
- 모델은 전역변수로 불러와야 한다. 만약 inference를 할 때마다 모델을 불러오도록 한다면 그로 인해 발생하는 시간이나 자원 등의 낭비가 발생합니다.
- 일반적으로 요청을 처리하기 전에 모델을 불러 옵니다.

```python
    def initialize(self, ):
        # De-serializing model and loading vectorizer
        import joblib
        self.model = joblib.load('model/ml_model.pkl')
        self.vectorizer = joblib.load('model/ml_vectorizer.pkl')
```

### Preprocess()
- Raw input을 전처리 및 모델 입력 가능형태로 변환
1. Raw input 전처리
    - 데이터 클린징의 목적과 학습 된 모델의 학습 당시 scaling이나 처리 방식과 맞춰주는 것이 필요
2. 모델에 입력가능한 형태로 변환(vectorization, converting to id)등의 작업

```python
    def preprocess(self, text):
        # cleansing raw text
        model_input = self._clean_text(text)

        # vectorizing cleaned text
        model_input = self.vectorizer.transform(model_input)
        return model_input
```

### inference()
- 입력된 값에 대한 예측/추론
1. 각 모델의 predict 방식으로 예측 확률분포 값 반환

```python
    def inference(self, model_input):
        # get predictions from model as probabilities
        model_output = self.model.predict_proba(model_input)
        return model_output
```

### postprocess()
- 모델의 예측값을 response에 맞게 후처리 작업
1. 예측된 결과에 대한 후처리 작업
2. 보통 모델이 반환하는 건 확률 분포와 같은 값이기 때문에 response에서 받아야 하는 정보로 처리하는 역할을 많이 함

```python
    def postprocess(self, model_output):
        # process predictions to predicted label and output format
        predicted_probabilities = model_output.max(axis = 1)
        predicted_ids = model_output.argmax(axis = 1)
        predicted_labels = [self.id2label[id_] for id_ in predicted_ids]
        return predicted_labels, predicted_probabilities
```

### 종합

```python
class MLModelHandler(ModelHandler):
    def __init__(self):
        super().__init__()
        self.initialize()

    def initialize(self, ):
        # De-serializing model and loading vectorizer
        import joblib
        self.model = joblib.load('model/ml_model.pkl')
        self.vectorizer = joblib.load('model/ml_vectorizer.pkl')
        
        pass

    def preprocess(self, text):
        # cleansing raw text
        model_input = self._clean_text(text)

        # vectorizing cleaned text
        model_input = self.vectorizer.transform(model_input)
        return model_input

    def inference(self, model_input):
        # get predictions from model as probabilities
        model_output = self.model.predict_proba(model_input)
        return model_output

    def postprocess(self, model_output):
        # process predictions to predicted label and output format
        predicted_probabilities = model_output.max(axis = 1)
        predicted_ids = model_output.argmax(axis = 1)
        predicted_labels = [self.id2label[id_] for id_ in predicted_ids]
        return predicted_labels, predicted_probabilities

    def handle(self, data):
        # do above processes
        model_input = self.preprocess(data)
        model_output = self.inference(model_input)
        return self.postprocess(model_output)
```