---
category: programmers
tags: [K-digital training, week5_day1, ml_basics, 확률이론]
use_math: true
---
 
## 확률이론 (Probability Theory)

### 확률변수(Random Variable)
- 확률변수 $X$는 표본의 집합 $S$의 원소 $e$를 실수 값 $X(e) = x$에 대응시키는 함수이다.
    - 대문자 $X,Y,...$ : 확률변수
    - 소문자 $x, y, ...$ : 확률변수가 가질 수 있는 값
    - 확률 $P$는 집합 $S$의 부분집합을 실수 값에 대응시키는 함수
        - $P[X=x]$
        - $P[X \le x]$
        - $X = x, X \le x$는 집합 $S$의 부분집합을 정의한다.

### 연속확률변수(Continuous Random Variables)
- 누적분포함수(cumulative distribution funcion, CDF): $F(x) = P[X \in (-\infty,x)]$
- 누적분포함수 $F(x)$를 가진 확률변수 $X$에 대해서 다음을 만족하는 함수 $f(x)$가 존재한다면 $X$를 연속확률 변수라고 부르고 $f(x)$를 X의 확률밀도함수(probability density function, pdf)라고 부른다. $F(x) = \int_{-\infty}^xf(t)dt$
- 확률변수를 명확히 하기 위해 $F_X(s), f_x(x)$로 쓰기도 한다.
- 혼란이 없을 경우 $f_X(x)$대신 $p_X(x), p_x(x), p(x)$를 사용하기도 한다.
- $p(x) \ge 0, \int_{-\infty}^{\infty}p(x) = 1$

### 확률변수의 성질(The Rules of Probability)
- 덧셈법칙(sum rule): 두 개의 확률변수 X,Y에 대한 확률은 Y에 대해서 이산확률변수인 경우에는 합을 구하고, 연속확률변수인 경우 적분을 하게 되면 X의 확률을 구할수 있다.(주변화)
    - $p(x) = \sum_Yp(X,Y)$
- 곱셈법칙(product rule): 
    - $p(X,Y) = p(X \vert Y)p(Y) + p(Y \vert X)p(X)$
- 베이즈 확률(Baeys):
    - $p(Y \vert X) = \frac {p(X \vert Y)p(Y)}{\sum_Y p(X \vert Y) p(Y)} $
    - $posterior = \frac {likelihood \times prior} {normalization}$
        - Posterior : 사후확률
        - likelihood : 가능도(우도)
        - prior : 사전확률
        - normalization : Y와 상관없는 상수, X의 경계확률(marginal) $p(X)$

### 확률변수의 함수(Functions of Random Variables)
- 확률변수 $X$의 함수 $Y = f(X)$도 확률변수이다(함수의 함수). 예를 들어 확률변수 $X$가 주(week)의 수로 표현되었다라고 할 때 일(day)의 수로 표현된 새로운 확률변수를 정의할 수 있다.
    - $Y = 7X$
    - $P[14 \le 21] = P[2 \le 3]$
- 확률변수 X의 함수 $Y=g(X)$와 역함수 $w(Y) = X$가 주어졌을 때 다음이 성립한다.
    - $ p_y(y) = p_x(x)\vert {dx \over dy} \vert $

- k차원의 확률변수 벡터 $x = (x_1, ..., x_k)$가 주어졌을 때, k개의 x에 관한 함수들 $y_i = g_i(x) for i = 1, ..., k$는 새로운 확률변수벡터 $ y = (y_1, ..., y_k)$를 정의한다. 간략하게 $y = g(x)$로 나타낼 수 있다. 만약, $y = g(x)$가 일대일(one-to-one)변환일 경우, y의 결합확률 밀도함수 (joint pdf)는   
<img width="223" alt="스크린샷 2021-01-04 오전 11 49 49" src="https://user-images.githubusercontent.com/51064261/103496840-ffd81b80-4e82-11eb-963e-5e0703d69d36.png">

- Inverse CDF Technique
    - 확률변수 $X$가 CDF $F_X(x)$를 가진다고 하자. 연속확률분포함수 U ~ UNIF(0,1)(0부터 1까지의 값이 1인 형태)의 함수로 정의되는 다음 확률변수 Y를 생각해보자.
        - $Y = F_X^{-1}(U)$
    - 확률변수 $Y$는 확률변수 $X$와 동일한 분포를 따르게 된다.
        - $F_Y(y) = P[Y \le y] = P[F_X^{-1}(U) \le y] = P[U \le F_X(y)] = F_X(y)$

### 기대값(Expectations)
- 기대값: 확률분포 $p(X)$하에서 함수 $f(x)$의 평균값
- 이산확률분포(discrete distribution) : $\mathbb E[f] = \sum_xp(x)f(x)$
- 연속확률분포(continous distribution) : $\mathbb E[f] = \int p(x)f(x)$
- 확률분포로부터 N개의 샘플을 추출해서 기댓값을 근사할 수 있다.
    - $\mathbb E[f] \approx {1 \over N}\sum_1^Nf(x_n)$
- 여러개 변수들의 함수
    - $\mathbb E_x[f(x, y)] = \sum_xf(x, y)p(x)$
    - y에 대한 함수임을 상기할 것.
    - $\mathbb E_{x,y}[f(x, y)] = \sum_y \sum_xf(x, y)p(x, y)$
- 조건부 기대값(conditional expectation):
    - $\mathbb E_x[f \vert y] = \sum_xf(x)p(x \vert y)$


### 분산(Variance), 공분산(covariance)
- $f(x)$의 분산(variance): $f(x)$의 값들이 기댓값 $\mathbb E[f]$으로부터 흩어져 있는 정도
    - $var[f] = \mathbb E[(f(x) - \mathbb E[f(x)])^2] = \mathbb E[f(x)^2] - {\mathbb E[f(x)]}^2$ 
    - $var[x] = \mathbb E[x^2] - \mathbb E[x]^2$
- 두 개의 확률변수 x, y에 대한 공분산(covariance)
    - $cov[x,y] = \mathbb E_{x,y}[(x - \mathbb E[x])(y - \mathbb E[y]) ] = \mathbb E_{x,y}[xy^T] - \mathbb E[x]\mathbb E[y^T]$
    - $cov[x] \equiv cov[x,x]$

### 빈도주의 대 베이지안(Frequentist versus Bayesian)
- 확률을 해석하는 두 가지 다른 관점: 빈도주의(frequentist), 베이지안(Bayesian)
    - 빈도주의 : 반복가능한 사건들의 빈도수에 기반
    - 베이지안 : 불확실성을 정량적으로 표현
- 반복가능하지 않은 사건일 경우 : 북극 얼음이 이번 세기말까지 녹아 없어질 확률? 우리가 이미 알고 있는 정보(얼음이 녹고있는 속도)에 근거해 확률을 정량적으로 나타낼 수 있고, 새로 수집하는 정보에 따라 확률을 업데이트할 수 있다.
- 모델의 파라미터 w(예를들어 다항식 곡선 근사문제에서의 계수 w)에 대한 우리의 지식을 확률적으로 나타내고 싶다면?
    - w에 대한 사전지식 $p(w) \to  $사전확률(prior)
    - 새로운 데이터 $D = (t_1, ..., t_N)$를 관찰하고 난 뒤의 조건부확률 $p(D \vert w) \to $우도함수(likelihood function). 특정 w값에 대해 D의 관찰값이 얼마나 가능성이 있는지를 나타냄. w에 관한 함수임을 기억할 것.
    - $p(w \vert D) = \frac {p(D \vert w)p(w)}{p(D)}$
    - $p(w \vert D)$는 $D$를 관찰하고 난 뒤의 w에 대한 불확실성을 표현
    - 사후확률(posterior) $\propto$ 우도(likelihood) $\times$ 사전확률(prior)
- 반면, 빈도주의는 w가 고정된 파라미터이고 최대우도와 같은 '추정자(estimatior)'를 사용해서 그 값을 구한다. 구해진 파라미터의 불확실성은 부트스트랩(bootstrap) 방법을 써서 구할 수 있다.
- 베이지안 관점의 장점
    - 사전확률을 모델에 포함시킬 수 있다.
    - 동전을 던져서 세번 모두 앞면이 나왔을 때
        - 최대우도 : 앞 면이 나올 확률은 1이 됨
        - 베이지안 : 극단적인 확률을 피할 수 있음

### 정규분포(Gaussian Distribution)
- 단일변수 x를 위한 가우시안 분포
    - $N(x \vert \mu, \sigma^2) = {1 \over (2\pi\sigma^2)^{1 \over 2}}exp(-{1 \over 2\sigma^2}(x - \mu)^2 )$
- 정규분포(Gaussian Distribution) : 기댓값(Expectation)
    - $E[x] = \int_{-\infty}^\infty N(x \vert \mu, \sigma^2)xdx = \mu$
- 정규분포(Gaussian Distribution) : 분산(Variance)
    - $var[x] = \sigma^2$
- 정규분포(Gaussian Distribution) : 최대우도해(Maximum Likelihood solution)
    - $X = (x_1, ..., x_N)^T$가 독립적으로 같은 가우시안분포로부터 추출된 N개의 샘플들이라고 할 때,
    - $p(X \vert \mu, \sigma^2) = p(x_1, ..., x_N \vert \mu, \sigma^2) = \prod_{n=1}^N N(x_N\vert \mu,\sigma^2)$
    - $\ln p(X \vert \mu, \sigma^2) = -{1\over 2 \sigma^2}\sum_{n=1}^N(x_n - \mu)^2 - {N \over 2}\ln\sigma^2 - {N \over 2}\ln(2\pi)$를 양변 $\mu$로 미분하여 0을 만드는 최대값을 찾음
    - $\mu_{ML} = {1\over N}\sum_{n=1}^Nx_n$
    - 같은 방식으로,
    - $\sigma_{ML}^2 = {1 \over N}\sum_{n=1}^N(x_n-\mu_{ML})^2$