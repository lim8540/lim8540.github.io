I"Šd<p>ë°€ë„ì¶”ì •(Density Estimation): $N$ê°œì˜ ê´€ì°°ë°ì´í„°(observations) $\mathbf{x}_1,\ldots\mathbf{x}_N$ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ë¶„í¬í•¨ìˆ˜ $p(\mathbf{x})$ë¥¼ ì°¾ëŠ” ê²ƒ</p>

<ol>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$p(\mathbf{x})$ë¥¼ íŒŒë¼ë¯¸í„°í™”ëœ ë¶„í¬ë¡œ ê°€ì •í•œë‹¤. íšŒê·€, ë¶„ë¥˜ë¬¸ì œì—ì„œëŠ” ì£¼ë¡œ $p(t</td>
          <td>\mathbf{x})$, $p(\mathcal{C}</td>
          <td>\mathbf{x})$ë¥¼ ì¶”ì •í•œë‹¤.</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>ê·¸ ë‹¤ìŒ ë¶„í¬ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ”ë‹¤.
    <ul>
      <li>ë¹ˆë„ì£¼ì˜ ë°©ë²•(Frequentistâ€™s way): ì–´ë–¤ ê¸°ì¤€(ì˜ˆë¥¼ ë“¤ì–´ likelihood)ì„ ìµœì í™”ì‹œí‚¤ëŠ” ê³¼ì •ì„ í†µí•´ íŒŒë¼ë¯¸í„° ê°’ì„ ì •í•œë‹¤. íŒŒë¼ë¯¸í„°ì˜ í•˜ë‚˜ì˜ ê°’ì„ êµ¬í•˜ê²Œ ëœë‹¤.</li>
      <li>ë² ì´ì§€ì–¸ ë°©ë²•(Bayesian way): ë¨¼ì € íŒŒë¼ë¯¸í„°ì˜ ì‚¬ì „í™•ë¥ (prior distribution)ì„ ê°€ì •í•˜ê³  Bayesâ€™ ruleì„ í†µí•´ íŒŒë¼ë¯¸í„°ì˜ ì‚¬í›„í™•ë¥ (posterior distribution)ì„ êµ¬í•œë‹¤.</li>
    </ul>
  </li>
  <li>íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•˜ë‹¤ë©´(í•œ ê°œì˜ ê°’ì´ë“  ë¶„í¬ë“ ) ê·¸ê²ƒì„ ì‚¬ìš©í•´ â€œì˜ˆì¸¡â€í•  ìˆ˜ ìˆë‹¤($t$ë‚˜ $\mathcal{C}$).</li>
</ol>

<p>ì¼¤ë ˆì‚¬ì „ë¶„í¬(Conjugate Prior): ì‚¬í›„í™•ë¥ ì´ ì‚¬ì „í™•ë¥ ê³¼ ë™ì¼í•œ í•¨ìˆ˜í˜•íƒœë¥¼ ê°€ì§€ë„ë¡ í•´ì¤€ë‹¤.</p>

<h2 id="ì´í•­ë³€ìˆ˜binary-variables-ë¹ˆë„ì£¼ì˜-ë°©ë²•">ì´í•­ë³€ìˆ˜(Binary Variables): ë¹ˆë„ì£¼ì˜ ë°©ë²•</h2>

<p>ì´í•­ í™•ë¥ ë³€ìˆ˜(binary random variable) $x\in {0, 1}$ (ì˜ˆë¥¼ ë“¤ì–´ ë™ì „ë˜ì§€ê¸°)ê°€ ë‹¤ìŒì„ ë§Œì¡±í•œë‹¤ê³  í•˜ì.</p>

\[p(x=1 | \mu) = \mu, p(x=0 | \mu) = 1 - \mu\]

<p>$p(x)$ëŠ” ë² ë¥´ëˆ„ì´ ë¶„í¬(Bernoulli distribution)ë¡œ í‘œí˜„ë  ìˆ˜ ìˆë‹¤.</p>

\[\mathrm{Bern}(x | \mu) = \mu^x (1-\mu)^{1-x}\]

<p>ê¸°ëŒ“ê°’, ë¶„ì‚°</p>

<ul>
  <li>$\mathbb{E}[x] = \mu$</li>
  <li>$\mathrm{var}[x] = \mu(1-\mu)$</li>
</ul>

<p>ìš°ë„í•¨ìˆ˜ (Likelihood Function)</p>

<table>
  <tbody>
    <tr>
      <td>$x$ê°’ì„ $N$ë²ˆ ê´€ì°°í•œ ê²°ê³¼ë¥¼ $\mathcal{D} = {x_1,\ldots,x_N}$ë¼ê³  í•˜ì. ê° $x$ê°€ ë…ë¦½ì ìœ¼ë¡œ $p(x</td>
      <td>\mu)$ì—ì„œ ë½‘í˜€ì§„ë‹¤ê³  ê°€ì •í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ìš°ë„í•¨ìˆ˜($\mu$ì˜ í•¨ìˆ˜ì¸)ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤.</td>
    </tr>
  </tbody>
</table>

\[p(\mathcal{D}|\mu) = \prod_{n=1}^N p(x_n|\mu) = \prod_{n=1}^N \mu^{x_n} (1-\mu)^{1-x_n}\]

<p><strong>ë¹ˆë„ì£¼ì˜ ë°©ë²•</strong>ì—ì„œëŠ” $\mu$ê°’ì„ ì´ ìš°ë„í•¨ìˆ˜ë¥¼ ìµœëŒ€í™”ì‹œí‚¤ëŠ” ê°’ìœ¼ë¡œ êµ¬í•  ìˆ˜ ìˆë‹¤. ë˜ëŠ” ì•„ë˜ì™€ ê°™ì´ ë¡œê·¸ìš°ë„í•¨ìˆ˜ë¥¼ ìµœëŒ€í™”ì‹œí‚¬ ìˆ˜ë„ ìˆë‹¤.</p>

\[\ln p(\mathcal{D}|\mu) = \sum_{n=1}^N \ln p(x_n|\mu) = \sum_{n=1}^N \{x_n\ln \mu + (1-x_n)\ln(1-\mu)\}\]

<p>$\mu$ì˜ ìµœëŒ€ìš°ë„ ì¶”ì •ì¹˜(maximum likelihood estimate)ëŠ”</p>

\[\mu^{\mathrm{ML}} = \frac{m}{N} ~~\mathrm{with}~~ m = (\#\mathrm{observations~of}~ x=1)\]

<p>$N$ì´ ì‘ì€ ê²½ìš°ì— ìœ„ MLEëŠ” ê³¼ì í•©(overfitting)ëœ ê²°ê³¼ë¥¼ ë‚³ì„ ìˆ˜ ìˆë‹¤. $N = m = 3 \to \mu^{\mathrm{ML}} = 1$!</p>

<h2 id="ì´í•­ë³€ìˆ˜binary-variables-ë² ì´ì§€ì–¸-ë°©ë²•">ì´í•­ë³€ìˆ˜(Binary Variables): ë² ì´ì§€ì–¸ ë°©ë²•</h2>

<p>ì´í•­ë¶„í¬ (Binomial Distribution)</p>

<p>$\mathcal{D} = {x_1,\ldots,x_N}$ì¼ ë•Œ, ì´í•­ë³€ìˆ˜ $x$ê°€ 1ì¸ ê²½ìš°ë¥¼ $m$ë²ˆ ê´€ì°°í•  í™•ë¥ </p>

\[\mathrm{Bin}(m|N,\mu) = {N \choose m}\mu^m(1-\mu)^{N-m}\]

\[{N \choose m} = \frac{N!}{(N-m)!m!}\]

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$\mathbb{E}[m] = \sum_{m=0}^N m\mathrm{Bin}(m</td>
          <td>N,\mu) = N\mu$</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>$\mathrm{var}[m] = \sum_{m=0}^N (m-\mathbb{E}[m])^2\mathrm{Bin}(m</td>
          <td>N,\mu) = N\mu(1-\mu)$</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p>ë°ì´í„°ë¥¼ ë³´ëŠ” ê´€ì </p>
<ul>
  <li>ë² ë¥´ëˆ„ì´ ì‹œí–‰ì˜ ë°˜ë³µ: $x_1,\ldots,x_N$ ê°ê°ì´ í™•ë¥ ë³€ìˆ˜</li>
  <li>$x$ê°€ 1ì¸ ê²½ìš°ë¥¼ ëª‡ ë²ˆ ê´€ì°°í–ˆëŠ”ê°€?: í•˜ë‚˜ì˜ í™•ë¥ ë³€ìˆ˜ $m$</li>
</ul>

<p>ë² ì´ì§€ì•ˆ ë°©ë²•ì„ ì“°ê¸° ìœ„í•´ì„œ ë°ì´í„°ì˜ ìš°ë„ë¥¼ êµ¬í•´ì•¼ í•˜ëŠ”ë° ì´í•­ë¶„í¬ë¥¼ ê°€ì •í•˜ë©´ ìš°ë„í•¨ìˆ˜ê°€ í•˜ë‚˜ì˜ ë³€ìˆ˜ $m$ìœ¼ë¡œ($x_1,\ldots,x_N$ ëŒ€ì‹ ) í‘œí˜„ê°€ëŠ¥í•˜ë¯€ë¡œ ê°„í¸í•´ì§„ë‹¤.</p>

<p>ë² íƒ€ë¶„í¬ (Beta Distribution)</p>

<p>ë² ì´ì§€ì–¸ ë°©ë²•ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë² íƒ€ë¶„í¬ë¥¼ ì¼¤ë ˆì‚¬ì „ë¶„í¬(conjugate prior)ë¡œ ì‚¬ìš©í•œë‹¤.</p>

\[\mathrm{Beta}(\mu|a,b) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}\]

<p>ê°ë§ˆí•¨ìˆ˜ $\Gamma(x)$ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤.</p>

\[\Gamma(x) = \int_0^{\infty}u^{x-1}e^{-u}\mathrm{d}u\]

<p>ê°ë§ˆí•¨ìˆ˜ëŠ” ê³„ìŠ¹(factorial)ì„ ì‹¤ìˆ˜ë¡œ í™•ì¥ì‹œí‚¨ë‹¤. $\Gamma(n) = (n-1)!$</p>

<h4 id="gammax--x-1gammax-1ì„ì„-ì¦ëª…í•˜ê¸°">$\Gamma(x) = (x-1)\Gamma(x-1)$ì„ì„ ì¦ëª…í•˜ê¸°</h4>

<p>Using integration by parts $\int_0^{\infty}a\mathrm{d}b = \left. ab\right\vert_0^{\infty} - \int_0^{\infty}b\mathrm{d}a$</p>

<p>\begin{align<em>}
a &amp;= u^{x-1} &amp;\mathrm{d}b &amp;= -e^{-u}\mathrm{d}u<br />
b &amp;= e^{-u} &amp;\mathrm{d}a &amp;= (x-1)u^{x-2}\mathrm{d}u<br />
\Gamma(x) &amp;= \left. u^{x-1}(-e^{-u})\right\vert_0^{\infty} + \int_0^{\infty} (x-1)u^{x-2}e^{-u}\mathrm{d}u<br />
&amp;= 0 + (x-1)\Gamma(x-1)
\end{align</em>}</p>

<table>
  <tbody>
    <tr>
      <td>ë² íƒ€ë¶„í¬ê°€ normalizedì„ì„ ì¦ëª…í•˜ê¸° ($\int_0^{1}\mathrm{Beta}(\mu</td>
      <td>a,b)\mathrm{d}\mu = 1$)</td>
    </tr>
  </tbody>
</table>

<p>$\int_0^1 \mu^{a-1}(1-\mu)^{b-1}\mathrm{d}\mu = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}$ì„ì„ ì¦ëª…í•˜ë©´ ëœë‹¤.</p>

<p>\begin{align<em>}
\Gamma(a)\Gamma(b) &amp;= \int_0^{\infty} x^{a-1}e^{-x}\mathrm{d}x\int_0^{\infty} y^{b-1}e^{-y}\mathrm{d}y<br />
&amp;= \int_0^{\infty}\int_0^{\infty}e^{-x-y}x^{a-1}y^{b-1}\mathrm{d}y\mathrm{d}x<br />
&amp;= \int_0^{\infty}\int_0^{\infty}e^{-t}x^{a-1}(t-x)^{b-1}\mathrm{d}t\mathrm{d}x &amp;\mathrm{by}~ t=y+x, \mathrm{d}t = \mathrm{d}y<br />
&amp;= \int_0^{\infty}\int_0^{\infty}e^{-t}x^{a-1}(t-x)^{b-1}\mathrm{d}x\mathrm{d}t<br />
&amp;= \int_0^{\infty}e^{-t}\int_0^{\infty}x^{a-1}(t-x)^{b-1}\mathrm{d}x\mathrm{d}t<br />
&amp;= \int_0^{\infty}e^{-t}\int_0^1(t\mu)^{a-1}(t-t\mu)^{b-1}t\mathrm{d}\mu\mathrm{d}t &amp;\mathrm{by}~ x=t\mu, \mathrm{d}x = t\mathrm{d}\mu<br />
&amp;= \int_0^{\infty}e^{-t}t^{a-1}t^{b-1}t\left(\int_0^1 \mu^{a-1}(1-\mu)^{b-1}\mathrm{d}\mu\right)\mathrm{d}t<br />
&amp;= \int_0^{\infty}e^{-t}t^{a+b-1}\mathrm{d}t\int_0^1\mu^{a-1}(1-\mu)^{b-1}\mathrm{d}\mu<br />
&amp;= \Gamma(a+b)\int_0^1\mu^{a-1}(1-\mu)^{b-1}\mathrm{d}\mu
\end{align</em>}</p>

<p>ë”°ë¼ì„œ, $\int_0^1 \mu^{a-1}(1-\mu)^{b-1}\mathrm{d}\mu = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}$ì´ ì„±ë¦½í•œë‹¤.</p>

<p>ê¸°ëŒ“ê°’, ë¶„ì‚°</p>

<ul>
  <li>$\mathbb{E}[\mu] = \frac{a}{a+b}$</li>
  <li>$\mathrm{var}[\mu] = \frac{ab}{(a+b)^2(a+b+1)}$</li>
</ul>

<p>$\mu$ì˜ ì‚¬í›„í™•ë¥  (posterior)</p>

<p>\begin{align<em>}
p(\mu | m, l, a, b) &amp;= \frac{\textrm{Bin}(m|N,\mu)\textrm{Beta}(\mu|a,b)}{\int_0^1 \textrm{Bin}(m|N,\mu)\textrm{Beta}(\mu|a,b)\textrm{d}\mu}<br />
&amp;= \frac{\mu^{m+a-1}(1-\mu)^{l+b-1}}{\int_0^1 \mu^{m+b-1}(1-\mu)^{l+b-1}\textrm{d}\mu}<br />
&amp;= \frac{\mu^{m+a-1}(1-\mu)^{l+b-1}}{\Gamma(m+a)\Gamma(l+b)/\Gamma(m+a+l+b)}<br />
&amp;= \frac{\Gamma(m+a+l+b)}{\Gamma(m+a)\Gamma(l+b)}\mu^{m+a-1}(1-\mu)^{l+b-1}
\end{align</em>}</p>

<p>ì˜ˆì¸¡ë¶„í¬ (predictive distribution)</p>

\[p(x=1 | \mathcal{D}) = \int_0^1 p(x=1|\mu)p(\mu|\mathcal{D})\mathrm{d}\mu = \int_0^1 \mu p(\mu|\mathcal{D})\mathrm{d}\mu = \mathbb{E}[\mu|\mathcal{D}]\]

\[p(x=1 | \mathcal{D}) = \frac{m+a}{m+a+l+b}\]

<h2 id="ë‹¤í•­ë³€ìˆ˜multinomial-variables-ë¹ˆë„ì£¼ì˜-ë°©ë²•">ë‹¤í•­ë³€ìˆ˜(Multinomial Variables): ë¹ˆë„ì£¼ì˜ ë°©ë²•</h2>

<p>$K$ê°œì˜ ìƒíƒœë¥¼ ê°€ì§ˆ ìˆ˜ ìˆëŠ” í™•ë¥ ë³€ìˆ˜ë¥¼ $K$ì°¨ì›ì˜ ë²¡í„° $\mathbf{x}$ (í•˜ë‚˜ì˜ ì›ì†Œë§Œ 1ì´ê³  ë‚˜ë¨¸ì§€ëŠ” 0)ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. ì´ëŸ° $\mathbf{x}$ë¥¼ ìœ„í•´ì„œ ë² ë¥´ëˆ„ì´ ë¶„í¬ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì¼ë°˜í™”ì‹œí‚¬ ìˆ˜ ìˆë‹¤.</p>

<p>\(p(\mathbf{x}|\pmb \mu) = \prod_{k=1}^K \mu_k^{x_k}\)
with $\sum_k \mu_k = 1$</p>

<p>$\mathbf{x}$ì˜ ê¸°ëŒ“ê°’
\(\mathbb{E}[\mathbf{x}|\pmb \mu] = \sum_{\mathbf{x}} p(\mathbf{x}|\pmb \mu) = (\mu_1,\ldots,\mu_M)^T = \pmb \mu\)</p>

<p>ìš°ë„í•¨ìˆ˜</p>

<p>${\bf x}$ê°’ì„ $N$ë²ˆ ê´€ì°°í•œ ê²°ê³¼ $\mathcal{D} = { {\bf x}_1,\ldots,{\bf x}_N }$ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ìš°ë„í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</p>

\[p(\mathcal{D}|\pmb \mu) = \prod_{n=1}^N\prod_{k=1}^K \mu_k^{x_{nk}} = \prod_{k=1}^K \mu_k^{(\sum_n x_{nk})} = \prod_{k=1}^K \mu_k^{m_k}\]

\[m_k = \sum_n x_{nk}\]

<table>
  <tbody>
    <tr>
      <td>$\mu$ì˜ ìµœëŒ€ìš°ë„ ì¶”ì •ì¹˜(maximum likelihood estimate)ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ì„  $\mu_k$ì˜ í•©ì´ 1ì´ ëœë‹¤ëŠ” ì¡°ê±´í•˜ì—ì„œ $\ln p(\mathcal{D}</td>
      <td>\pmb \mu)$ì„ ìµœëŒ€í™”ì‹œí‚¤ëŠ” $\mu_k$ë¥¼ êµ¬í•´ì•¼ í•œë‹¤. ë¼ê·¸ë‘ì£¼ ìŠ¹ìˆ˜(Lagrange multiplier) $\lambda$ë¥¼ ì‚¬ìš©í•´ì„œ ë‹¤ìŒì„ ìµœëŒ€í™”ì‹œí‚¤ë©´ ëœë‹¤.</td>
    </tr>
  </tbody>
</table>

\[\sum_{k=1}^K m_k \ln \mu_k + \lambda \left(\sum_{k=1}^K \mu_k -1\right)\]

\[\mu_k^{ML} = \frac{m_k}{N}\]

<h2 id="ë‹¤í•­ë³€ìˆ˜multinomial-variables-ë² ì´ì§€ì–¸-ë°©ë²•">ë‹¤í•­ë³€ìˆ˜(Multinomial Variables): ë² ì´ì§€ì–¸ ë°©ë²•</h2>

<p>ë‹¤í•­ë¶„í¬ (Multinomial distribution)</p>

<p>íŒŒë¼ë¯¸í„° $\pmb \mu$ì™€ ì „ì²´ ê´€ì°°ê°œìˆ˜ $N$ì´ ì£¼ì–´ì¡Œì„ ë•Œ $m_1,\ldots,m_K$ì˜ ë¶„í¬ë¥¼ ë‹¤í•­ë¶„í¬(multinomial distribution)ì´ë¼ê³  í•˜ê³  ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœë¥¼ ê°€ì§„ë‹¤.</p>

\[\mathrm{Mult}(m_1,\ldots,m_K|\pmb \mu,N) = {N \choose m_1m_2\ldots m_K} \prod_{k=1}^K \mu_k^{m_k}\]

\[{N \choose m_1m_2\ldots m_K} = \frac{N!}{m_1!m_2!\ldots m_K!}\]

\[\sum_{k=1}^K m_k= N\]

<p>ë””ë¦¬í´ë ˆ ë¶„í¬(Dirichlet distribution): ë‹¤í•­ë¶„í¬ë¥¼ ìœ„í•œ ì¼¤ë ˆì‚¬ì „ë¶„í¬</p>

\[\mathrm{Dir}(\pmb \mu|\mathbf{\alpha}) = \frac{\Gamma{\alpha_0}}{\Gamma(\alpha_1)\ldots\Gamma(\alpha_K)}\prod_{k=1}^K \mu_k^{\alpha_k-1}\]

\[\alpha_0 = \sum_{k=1}^K \alpha_k\]

<p>ë””ë¦¬í´ë ˆ ë¶„í¬ì˜ normalization ì¦ëª… ($K=3$)</p>

<p>ë‹¤ìŒ ê²°ê³¼ë¥¼ ì‚¬ìš©í•œë‹¤.</p>

<p>\begin{align<em>}
\int_L^U(x-L)^{a-1}(U-x)^{b-1}\mathrm{d}x &amp;= \int_0^1 (U-L)^{a-1}t^{a-1}(U-L)^{b-1}(1-t)^{b-1}(U-L)\mathrm{d}t &amp;\mathrm{by}~ t=\frac{x-L}{U-L}<br />
&amp;= (U-L)^{a+b-1}\int_0^1 t^{a-1}(1-t)^{b-1}\mathrm{d}t<br />
&amp;= (U-L)^{a+b-1}\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)}
\end{align</em>}</p>

<p>\begin{align<em>}
\int_0^{1-\mu_1}\mu_1^{\alpha_1-1}\mu_2^{\alpha_2-1}(1-\mu_1-\mu_2)^{\alpha_3-1}\mathrm{d}\mu_2 &amp;= \mu_1^{\alpha_1-1}\int_0^{1-\mu_1}\mu_2^{\alpha_2-1}(1-\mu_1-\mu_2)^{\alpha_3-1}\mathrm{d}\mu_2 &amp; \textrm{by}~ L=0, U=1-\mu_1<br />
&amp;= \mu_1^{\alpha_1-1}(1-\mu_1)^{\alpha_2+\alpha_3-1}\frac{\Gamma(\alpha_2)\Gamma(\alpha_3)}{\Gamma(\alpha_2+\alpha_3)}
\end{align</em>}</p>

<p>\begin{align<em>}
\int_0^1\int_0^{1-\mu_1}\mu_1^{\alpha_1-1}\mu_2^{\alpha_2-1}(1-\mu_1-\mu_2)^{\alpha_3-1}\mathrm{d}\mu_2\mathrm{d}\mu_1 &amp;= \frac{\Gamma(\alpha_2)\Gamma(\alpha_3)}{\Gamma(\alpha_2+\alpha_3)} \int_0^1 \mu_1^{\alpha_1-1}(1-\mu_1)^{\alpha_2+\alpha_3-1}\mathrm{d}\mu_1<br />
&amp;= \frac{\Gamma(\alpha_2)\Gamma(\alpha_3)}{\Gamma(\alpha_2+\alpha_3)} \frac{\Gamma(\alpha_1)\Gamma(\alpha_2+\alpha_3)}{\Gamma(\alpha_1+\alpha_2+\alpha_3)}<br />
&amp;= \frac{\Gamma(\alpha_1)\Gamma(\alpha_2)\Gamma(\alpha_3)}{\Gamma(\alpha_1+\alpha_2+\alpha_3)}
\end{align</em>}</p>

<p>$\mu$ì˜ ì‚¬í›„í™•ë¥  (posterior)</p>

<p>\begin{align<em>}
p(\pmb \mu|\mathcal{D},\mathbf{\alpha}) &amp;= \mathrm{Dir}(\pmb \mu|\mathbf{\alpha}+\mathbf{m})<br />
&amp;= \frac{\Gamma(\alpha_0+N)}{\Gamma(\alpha_1+m_1)\ldots\Gamma(\alpha_K+m_K)}\prod_{k=1}^K \mu_k^{\alpha_k+m_k-1}
\end{align</em>}</p>

\[\mathbf{m} = (m_1,\ldots,m_K)^T\]

<p>$\alpha_k$ë¥¼ $x_k=1$ì— ëŒ€í•œ ì‚¬ì „ê´€ì°° ê°œìˆ˜ë¼ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># for inline plots in jupyter
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c1"># import matplotlib
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="c1"># for latex equations
</span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Math</span><span class="p">,</span> <span class="n">Latex</span>
<span class="c1"># for displaying images
</span><span class="kn">from</span> <span class="nn">IPython.core.display</span> <span class="kn">import</span> <span class="n">Image</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import seaborn
</span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="c1"># settings for seaborn plotting style
</span><span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">color_codes</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># settings for seaborn plot sizes
</span><span class="n">sns</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s">'figure.figsize'</span><span class="p">:(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)})</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<h2 id="uniform-distribution">Uniform Distribution</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># import uniform distribution
</span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">uniform</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># random numbers from uniform distribution
</span><span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">start</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">width</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">data_uniform</span> <span class="o">=</span> <span class="n">uniform</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">loc</span> <span class="o">=</span> <span class="n">start</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">width</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_uniform</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([17.20884826, 24.93936496, 20.16385564, ..., 25.84009642,
       11.38092608, 13.44157615])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data_uniform</span><span class="p">,</span>
                  <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                  <span class="n">kde</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                  <span class="n">color</span><span class="o">=</span><span class="s">'skyblue'</span><span class="p">,</span>
                  <span class="n">hist_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"linewidth"</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span><span class="s">'alpha'</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
<span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">'Uniform Distribution '</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">'Frequency'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Text(0, 0.5, 'Frequency'), Text(0.5, 0, 'Uniform Distribution ')]
</code></pre></div></div>

<p><img src="ML_Probability_1_files/ML_Probability_1_13_1.png" alt="png" /></p>

<h2 id="bernoulli-distribution">Bernoulli Distribution</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">bernoulli</span>
<span class="n">data_bern</span> <span class="o">=</span> <span class="n">bernoulli</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span><span class="n">p</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">data_bern</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([0, 1]), array([1963, 8037]))
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ax</span><span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data_bern</span><span class="p">,</span>
                 <span class="n">kde</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s">"skyblue"</span><span class="p">,</span>
                 <span class="n">hist_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"linewidth"</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span><span class="s">'alpha'</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
<span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">'Bernoulli Distribution'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">'Frequency'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Text(0, 0.5, 'Frequency'), Text(0.5, 0, 'Bernoulli Distribution')]
</code></pre></div></div>

<p><img src="ML_Probability_1_files/ML_Probability_1_17_1.png" alt="png" /></p>

<h2 id="beta-distribution">Beta Distribution</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">beta</span>
<span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span>
<span class="n">data_beta</span> <span class="o">=</span> <span class="n">beta</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_beta</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0.99580421, 0.2699958 , 0.07223109, ..., 0.99998619, 0.2966079 ,
       0.99999968])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ax</span><span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data_beta</span><span class="p">,</span>
                 <span class="n">kde</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                 <span class="n">color</span><span class="o">=</span><span class="s">"skyblue"</span><span class="p">,</span>
                 <span class="n">hist_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"linewidth"</span><span class="p">:</span> <span class="mi">15</span><span class="p">,</span><span class="s">'alpha'</span><span class="p">:</span><span class="mi">1</span><span class="p">})</span>
<span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">'Beta Distribution'</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">'Frequency'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Text(0, 0.5, 'Frequency'), Text(0.5, 0, 'Beta Distribution')]
</code></pre></div></div>

<p><img src="ML_Probability_1_files/ML_Probability_1_21_1.png" alt="png" /></p>

<h2 id="multinomial-distribution">Multinomial Distribution</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multinomial</span>
<span class="n">data_multinomial</span> <span class="o">=</span> <span class="n">multinomial</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_multinomial</span><span class="p">[:</span><span class="mi">50</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[0, 0, 1, 0],
       [0, 0, 1, 0],
       [1, 0, 0, 0],
       [0, 1, 0, 0],
       [1, 0, 0, 0],
       [1, 0, 0, 0],
       [0, 0, 1, 0],
       [0, 0, 0, 1],
       [0, 0, 1, 0],
       [0, 0, 1, 0],
       [0, 1, 0, 0],
       [0, 0, 0, 1],
       [1, 0, 0, 0],
       [0, 0, 1, 0],
       [0, 0, 0, 1],
       [0, 0, 0, 1],
       [0, 0, 0, 1],
       [0, 0, 0, 1],
       [1, 0, 0, 0],
       [0, 1, 0, 0],
       [0, 0, 0, 1],
       [0, 0, 1, 0],
       [0, 1, 0, 0],
       [0, 0, 0, 1],
       [0, 0, 1, 0],
       [0, 0, 1, 0],
       [0, 1, 0, 0],
       [0, 0, 1, 0],
       [0, 1, 0, 0],
       [0, 0, 0, 1],
       [0, 0, 0, 1],
       [1, 0, 0, 0],
       [0, 1, 0, 0],
       [0, 0, 0, 1],
       [0, 0, 0, 1],
       [0, 0, 1, 0],
       [0, 0, 0, 1],
       [0, 0, 1, 0],
       [0, 0, 1, 0],
       [1, 0, 0, 0],
       [0, 0, 0, 1],
       [0, 0, 0, 1],
       [1, 0, 0, 0],
       [0, 1, 0, 0],
       [0, 0, 0, 1],
       [0, 0, 1, 0],
       [0, 0, 1, 0],
       [0, 0, 1, 0],
       [0, 0, 0, 1],
       [0, 0, 0, 1]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
  <span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">unique</span><span class="p">(</span><span class="n">data_multinomial</span><span class="p">[:,</span><span class="n">i</span><span class="p">],</span> <span class="n">return_counts</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array([0, 1]), array([7970, 2030]))
(array([0, 1]), array([8985, 1015]))
(array([0, 1]), array([6975, 3025]))
(array([0, 1]), array([6070, 3930]))
</code></pre></div></div>

:ET