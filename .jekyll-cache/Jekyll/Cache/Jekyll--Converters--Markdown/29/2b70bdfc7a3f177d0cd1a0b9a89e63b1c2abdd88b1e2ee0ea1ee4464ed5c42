I"„N<h2 id="ìë™-ë¯¸ë¶„ê³¼-ê·¸ë˜ë””ì–¸íŠ¸-í…Œì´í”„">ìë™ ë¯¸ë¶„ê³¼ ê·¸ë˜ë””ì–¸íŠ¸ í…Œì´í”„</h2>

<h3 id="ê·¸ë ˆë””ì–¸íŠ¸-í…Œì´í”„">ê·¸ë ˆë””ì–¸íŠ¸ í…Œì´í”„</h3>
<ul>
  <li>í…ì„œí”Œë¡œëŠ” ìë™ë¯¸ë¶„ì„ ìœ„í•œ tf.GradientTape APIë¥¼ ì œê³µ</li>
  <li>tf.GradientTapeëŠ” ì»¨í…ìŠ¤íŠ¸ ì•ˆì—ì„œ ì‹¤í–‰ëœ ëª¨ë“  ì—°ì‚°ì„ í…Œì´í”„ì— ê¸°ë¡</li>
  <li>í›„ì§„ ë°©ì‹ ìë™ ë¯¸ë¶„(reverse mode differetiation)ì„ ì‚¬ìš©í•´ì„œ í…Œì´í”„ì— â€˜ê¸°ë¡ëœâ€™ì—°ì‚° ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import tensorflow as tf

print(tf.__version__)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2.4.0
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x = tf.ones((2, 2))
# 1, 1
# 1, 1

with tf.GradientTape() as t:
  t.watch(x)
  y = tf.reduce_sum(x)
  print('y :', y)
  z = tf.multiply(y, y)
  print('z :', z)

# ì…ë ¥ í…ì„œ xì— ëŒ€í•œ zì˜ ë„í•¨ìˆ˜
dz_dx = t.gradient(z, x)
print(dz_dx)
for i in [0, 1]:
  for j in [0, 1]:
    # AssertionErrorê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ
    assert dz_dx[i][j].numpy() == 8.0
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>y : tf.Tensor(4.0, shape=(), dtype=float32)
z : tf.Tensor(16.0, shape=(), dtype=float32)
tf.Tensor(
[[8. 8.]
 [8. 8.]], shape=(2, 2), dtype=float32)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x = tf.ones((2, 2))

with tf.GradientTape() as t:
  t.watch(x)
  y = tf.reduce_sum(x)
  z = tf.multiply(y, y)

# tf.GradientTape() ì•ˆì—ì„œ ê³„ì‚°ëœ ì¤‘ê°„ ê°’ì— ëŒ€í•œ ê·¸ë ˆë””ì–¸íŠ¸ë„ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# í…Œì´í”„ ì‚¬ìš©í•˜ì—¬ ì¤‘ê°„ê°’ yì— ëŒ€í•œ ë„í•¨ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. 
dz_dy = t.gradient(z, y)
assert dz_dy.numpy() == 8.0
</code></pre></div></div>

<ul>
  <li>GradientTape.gradient() ë©”ì†Œë“œê°€ í˜¸ì¶œë˜ë©´ GredientTapeì— í¬í•¨ëœ ë¦¬ì†ŒìŠ¤ê°€ í•´ì œë¨</li>
  <li>ë™ì¼í•œ ì—°ì‚°ì— ëŒ€í•´ ì—¬ëŸ¬ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ë ¤ë©´ ì§€ì†ì„±ìˆëŠ”(persistent=True) ê·¸ë˜ë””ì–¸íŠ¸ í…Œì´í”„ë¥¼ ìƒì„±í•˜ë©´ ë¨</li>
  <li>ì´ë ‡ê²Œ ìƒì„±í•œ ê·¸ë˜ë””ì–¸íŠ¸ í…Œì´í”„ë¥¼ gradient() ë©”ì†Œë“œì˜ ë‹¤ì¤‘ í˜¸ì¶œì„ í—ˆìš©</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x = tf.constant(3.0)
with tf.GradientTape(persistent=True) as t:
  t.watch(x)
  y = x * x
  z = y * y # z = x ^ 4
dz_dx = t.gradient(z, x)  # 108.0 (4*x^3 at x = 3)
print(dz_dx)
dy_dx = t.gradient(y, x)  # 6.0
print(dy_dx)
del t  # í…Œì´í”„ì— ëŒ€í•œ ì°¸ì¡°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(108.0, shape=(), dtype=float32)
tf.Tensor(6.0, shape=(), dtype=float32)
</code></pre></div></div>

<h3 id="ì œì–´-íë¦„-ê¸°ë¡">ì œì–´ íë¦„ ê¸°ë¡</h3>
<ul>
  <li>ì—°ì‚°ì´ ì‹¤í–‰ë˜ëŠ” ìˆœì„œëŒ€ë¡œ í…Œì´í”„ì— ê¸°ë¡ë˜ê¸° ë•Œë¬¸ì—, íŒŒì´ì¬ ì œì–´íë¦„ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬ë¨</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def f(x, y):
  output = 1.0
  for i in range(y):
    if i &gt; 1 and i &lt; 5: # output(1) * 2 * 3 * 4
      output = tf.multiply(output, x)
  return output

def grad(x, y):
  with tf.GradientTape() as t:
    t.watch(x)
    out = f(x, y)
  return t.gradient(out, x)

x = tf.convert_to_tensor(2.0)

print(grad(x, 6).numpy())
assert grad(x, 6).numpy() == 12.0

print(grad(x, 5).numpy())
assert grad(x, 5).numpy() == 12.0

print(grad(x, 4).numpy())
assert grad(x, 4).numpy() == 4.0
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>12.0
12.0
4.0
</code></pre></div></div>

<h3 id="ê³ ê³„ë„higher-order-ê·¸ë˜ë””ì–¸íŠ¸">ê³ ê³„ë„(Higher-order) ê·¸ë˜ë””ì–¸íŠ¸</h3>
<ul>
  <li>GradientTape í„´í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì•ˆì— ìˆëŠ” ì—°ì‚°ë“¤ì€ ìë™ë¯¸ë¶„ì„ ìœ„í•´ ê¸°ë¡ë¨</li>
  <li>ë§Œì•½ ì´ ì»¨í…ìŠ¤íŠ¸ ì•ˆì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ë©´ í•´ë‹¹ ê·¸ë˜ë””ì–¸íŠ¸ ì—°ì‚° ë˜í•œ ê¸°ë¡ë¨</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x = tf.Variable(1.0)  # 1.0ìœ¼ë¡œ ì´ˆê¸°í™”ëœ í…ì„œí”Œë¡œ ë³€ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

with tf.GradientTape() as t:
  with tf.GradientTape() as t2:
    y = x * x * x
  # 't' ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì•ˆì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
  # ì´ê²ƒì€ ë˜í•œ ê·¸ë˜ë””ì–¸íŠ¸ ì—°ì‚° ìì²´ë„ ë¯¸ë¶„ê°€ëŠ¥í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. 
  dy_dx = t2.gradient(y, x) # dy_dx = 3 * x^2 at x = 1
d2y_dx2 = t.gradient(dy_dx, x)  # d2y_dx2 = 6 * x  at x = 1

assert dy_dx.numpy() == 3.0
assert d2y_dx2.numpy() == 6.0
</code></pre></div></div>

<h2 id="annartificial-neural-network">ANN(Artificial Neural Network)</h2>

<h3 id="sequential-ëª¨ë¸ì„-ì‚¬ìš©í•˜ëŠ”-ê²½ìš°">Sequential ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°</h3>
<ul>
  <li>Sequential ëª¨ë¸ì€ ê° ë ˆì´ì–´ì— ì •í™•íˆ í•˜ë‚˜ì˜ ì…ë ¥ í…ì„œì™€ í•˜ë‚˜ì˜ ì¶œë ¥ í…ì„œê°€ ìˆëŠ” ì¼ë°˜ ë ˆì´ì–´ ìŠ¤íƒì— ì í•©</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Define Sequential model with 3 layers
model = keras.Sequential(
    [
        layers.Dense(2, activation="relu", name="layer1"),
        layers.Dense(3, activation="relu", name="layer2"),
        layers.Dense(4, name="layer3"),
    ]
)
# Call model on a test input
x = tf.ones((3, 3))
# [1, 1, 1] --&gt; [o, o] ==&gt; [o, o, o] --&gt; [o, o, o, o]
y = model(x)
print(y)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(
[[ 0.03789226  0.22684497  0.5104858  -0.10226724]
 [ 0.03789226  0.22684497  0.5104858  -0.10226724]
 [ 0.03789226  0.22684497  0.5104858  -0.10226724]], shape=(3, 4), dtype=float32)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Create 3 layers
# ìœ„ì˜ í•¨ìˆ˜ì™€ ë™ì¼
layer1 = layers.Dense(2, activation="relu", name="layer1")
layer2 = layers.Dense(3, activation="relu", name="layer2")
layer3 = layers.Dense(4, name="layer3")

# Call layers on a test input
x = tf.ones((3, 3))
y = layer3(layer2(layer1(x)))
print(y)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tf.Tensor(
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]], shape=(3, 4), dtype=float32)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># layers ì†ì„±ì„ ì‚¬ìš©í•´ì„œ ë ˆì´ì–´ì— ëŒ€í•´ ì ‘ê·¼í•  ìˆ˜ ìˆìŒ
model.layers
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;tensorflow.python.keras.layers.core.Dense at 0x7f493150e780&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f493150eac8&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f493150e908&gt;]
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># add() ë©”ì„œë“œë¥¼ í†µí•´ì„œ Sequential ëª¨ë¸ì„ ì ì§„ì ìœ¼ë¡œ ì‘ì„±í•  ìˆ˜ë„ ìˆìŒ
model = keras.Sequential()
model.add(layers.Dense(2, activation="relu"))
model.add(layers.Dense(3, activation="relu"))
model.add(layers.Dense(4))
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model.layers
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[&lt;tensorflow.python.keras.layers.core.Dense at 0x7f4931507828&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f49314bbcf8&gt;,
 &lt;tensorflow.python.keras.layers.core.Dense at 0x7f49314bb048&gt;]
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># pop() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ë ˆì´ì–´ë¥¼ ì œê±°í•  ìˆ˜ ìˆìŒ
model.pop()
print(len(model.layers))  # 2
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2
</code></pre></div></div>

<h2 id="íŒ¨ì„ -mnistë¥¼-ì‚¬ìš©í•œ-ë¶„ë¥˜-ë¬¸ì œ">íŒ¨ì„  MNISTë¥¼ ì‚¬ìš©í•œ ë¶„ë¥˜ ë¬¸ì œ</h2>
<ul>
  <li>íŒ¨ì…˜ MNIST ë°ì´í„°ì—ëŠ” 10ê°œì˜ ì¹´í…Œê³ ë¦¬ì™€ 70,000ê°œì˜ í‘ë°± ì´ë¯¸ì§€ê°€ í¬í•¨</li>
  <li>ì´ë¯¸ì§€ì˜ í•´ìƒë„ëŠ” 28*28</li>
  <li>ë„¤íŠ¸ì›Œí¬ í›ˆë ¨ì— 60,000ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ê³  , í‰ê°€ë¥¼ ìœ„í•´ 10,000ê°œë¥¼ ì‚¬ìš©</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># tensorflowì™€ tf.kerasë¥¼ ì„í¬íŠ¸ í•©ë‹ˆë‹¤.
import tensorflow as tf
from tensorflow import keras

# í—¬í¼(helper) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸ í•©ë‹ˆë‹¤.
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2.4.0
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fashion_mnist = keras.datasets.fashion_mnist

(train_images, train_labels), (Test_images, test_labels) = fashion_mnist.load_data()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>class_names = ['T_shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train_images.shape
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(60000, 28, 28)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>len(train_labels)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>60000
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()
print(class_names[train_labels[0]])
</code></pre></div></div>

<p><img src="/image/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_files/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_24_0.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ankle boot
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># ì‹ ê²½ë§ ëª¨ë¸ì— ì£¼ì…í•˜ê¸° ì „ì— ê°’ì˜ ë²”ìœ„ë¥¼ 0~1ë¡œ ì¡°ì •
train_images = train_images / 255.0
Test_images = Test_images / 255.0
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>plt.figure(figsize=(10,10))
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_images[i], cmap=plt.cm.binary)
  plt.xlabel(class_names[train_labels[i]])
plt.show()
</code></pre></div></div>

<p><img src="/image/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_files/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_26_0.png" alt="png" /></p>

<h3 id="ëª¨ë¸-êµ¬ì„±">ëª¨ë¸ êµ¬ì„±</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model = keras.Sequential([
  # í–‰ë ¬ì„ Flattenì„ í†µí•´ ë²¡í„°ë¡œ ë°”ê¿”ì¤Œ
  keras.layers.Flatten(input_shape=(28,28)),
  keras.layers.Dense(128, activation='relu'),
  keras.layers.Dense(10, activation='softmax')
])
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model.summary()
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
flatten (Flatten)            (None, 784)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 128)               100480    
_________________________________________________________________
dense_4 (Dense)              (None, 10)                1290      
=================================================================
Total params: 101,770
Trainable params: 101,770
Non-trainable params: 0
_________________________________________________________________
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>keras.utils.plot_model(model, show_shapes='True')
</code></pre></div></div>

<p><img src="/image/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_files/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_30_0.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model.compile(optimizer='adam', # SGD, SGD + momentum
              loss = 'sparse_categorical_crossentropy',
              metrics = ['accuracy'])
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model.fit(train_images, train_labels, epochs=5)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.6348 - accuracy: 0.7787
Epoch 2/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.3776 - accuracy: 0.8645
Epoch 3/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.3337 - accuracy: 0.8778
Epoch 4/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.3153 - accuracy: 0.8842
Epoch 5/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.2923 - accuracy: 0.8917





&lt;tensorflow.python.keras.callbacks.History at 0x7f49288094a8&gt;
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>test_loss, test_acc = model.evaluate(Test_images, test_labels, verbose = 2)

print("Test loss: ", test_loss)
print("Test accuracy: ", test_acc)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>313/313 - 0s - loss: 0.3540 - accuracy: 0.8699
Test loss:  0.35403791069984436
Test accuracy:  0.8698999881744385
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ ë§Œë“¤ê¸°
predictions = model.predict(Test_images)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ìˆëŠ” ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ì§„í–‰í•œ í›„, ì²«ë²ˆì§¸ ì˜ˆì¸¡ ê°’
# 10ê°œì˜ ì˜· í’ˆëª©ì— ìƒì‘í•˜ëŠ” ëª¨ë¸ì˜ ì‹ ë¢°ë„(confidence)ë¥¼ ë‚˜íƒ€ëƒ„
predictions[0]
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([1.7327739e-05, 2.0118584e-06, 2.0664031e-06, 7.5148918e-09,
       2.4433596e-06, 2.0490089e-02, 3.5083385e-06, 2.1663917e-02,
       3.7270427e-06, 9.5781487e-01], dtype=float32)
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># rkwkd shvdms tlsfhlehfmf rkwls fpdlqmf cnffur
np.argmax(predictions[0])
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>9
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ 0ë²ˆì§¸ ê°’
test_labels[0]
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>9
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 10ê°œì˜ í´ë˜ì„œì— ëŒ€í•œ ì˜ˆì¸¡ì„ ëª¨ë‘ ê·¸ë˜í”„ë¡œ í‘œí˜„
# ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡ëœ ë ˆì´ë¸”ì€ íŒŒë€ìƒ‰ìœ¼ë¡œ, ì˜ëª» ì˜ˆì¸¡ëœ ë ˆì´ë¸”ì€ ë¹¨ê°•ìƒ‰ìœ¼ë¡œ í‘œí˜„
# ìˆ«ìëŠ” ì˜ˆì¸¡ ë ˆì´ë¸”ì˜ ì‹ ë¢°ë„ í¼ì„¼íŠ¸
def plot_image(i, predictions_array, true_label, img):
  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  
  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'
  
  plt.xlabel("{} {:2.0f}% ({})".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  predictions_array, true_label = predictions_array[i], true_label[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color="#777777")
  plt.ylim([0, 1]) 
  predicted_label = np.argmax(predictions_array)
 
  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 0ë²ˆì§¸ ì›ì†Œì˜ ì´ë¯¸ì§€, ì˜ˆì¸¡, ì‹ ë¢°ë„ ì ìˆ˜ ë°°ì—´
i = 0
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions, test_labels, Test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions, test_labels)
plt.show()
</code></pre></div></div>

<p><img src="/image/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_files/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_39_0.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 0ë²ˆì§¸ ì›ì†Œì˜ ì´ë¯¸ì§€, ì˜ˆì¸¡, ì‹ ë¢°ë„ ì ìˆ˜ ë°°ì—´
i = 40
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions, test_labels, Test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions, test_labels)
plt.show()
</code></pre></div></div>

<p><img src="/image/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_files/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_40_0.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># ì²˜ìŒ x ê°œì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì™€ ì˜ˆì¸¡ ë ˆì´ë¸”, ì§„ì§œ ë ˆì´ë¸”ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize = (2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows,2*num_cols,2*i+1)
  plot_image(i+40, predictions, test_labels, Test_images)
  plt.subplot(num_rows,2*num_cols,2*i+2)
  plot_value_array(i+40, predictions, test_labels)
plt.show()
</code></pre></div></div>

<p><img src="/image/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_files/Tensorflow_Tutorial%28GradientTape%2C_MLP%29_41_0.png" alt="png" /></p>

:ET