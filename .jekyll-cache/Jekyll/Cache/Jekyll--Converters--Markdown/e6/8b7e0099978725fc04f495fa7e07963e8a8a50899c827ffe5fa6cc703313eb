I"<h2 id="엔트로피">엔트로피</h2>

<ul>
  <li>자기정보(self-information) : $i(A)$
    <ul>
      <li>A : 사건</li>
      <li>$ i(A) = {log_b({1\over {P(A)}})} = -log_bP(A)$</li>
      <li>확률이 높은 사건:
        <ul>
          <li>정보가 많지 않음</li>
          <li>예 : 도둑이 들었는데 개가 짖는 경우보다 도둑이 들었는데 개가 안 짖는 경우 더 많은 정보를 포함하고 있음</li>
        </ul>
      </li>
      <li>정보의 단위
        <ul>
          <li>b = 2 : bits</li>
          <li>b = e : nats</li>
          <li>b = 10 : hartley</li>
        </ul>
      </li>
      <li>특성
        <ul>
          <li>$ i(AB) ={log_b({1\over {P(A)P(B)}})} = {log_b({1\over {P(A)}})} + {log_b({1\over {P(B)}})} = i(A) + i(B)$</li>
          <li>따라서, 두 사건이 동시에 있어났을 때, 자기정보는 각 자기정보의 합과 같다.</li>
          <li>$ P(H) = {1\over8}, P(T) = {7\over8} $
            <ul>
              <li>$ i(H) = -log_bP(H) = -log_2{1 \over 8} = 3비트$</li>
              <li>$ i(H) = -log_bP(T) = -log_2{7 \over 8} = 0.193비트$</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

:ET