I"$<h2 id="확률이론-probability-theory">확률이론 (Probability Theory)</h2>

<h3 id="확률변수random-variable">확률변수(Random Variable)</h3>
<ul>
  <li>확률변수 $X$는 표본의 집합 $S$의 원소 $e$를 실수 값 $X(e) = x$에 대응시키는 함수이다.
    <ul>
      <li>대문자 $X,Y,…$ : 확률변수</li>
      <li>소문자 $x, y, …$ : 확률변수가 가질 수 있는 값</li>
      <li>확률 $P$는 집합 $S$의 부분집합을 실수 값에 대응시키는 함수
        <ul>
          <li>$P[X=x]$</li>
          <li>$P[X \le x]$</li>
          <li>$X = x, X \le x$는 집합 $S$의 부분집합을 정의한다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="연속확률변수continuous-random-variables">연속확률변수(Continuous Random Variables)</h3>
<ul>
  <li>누적분포함수(cumulative distribution funcion, CDF): $F(x) = P[X \in (-\infty,x)]$</li>
  <li>누적분포함수 $F(x)$를 가진 확률변수 $X$에 대해서 다음을 만족하는 함수 $f(x)$가 존재한다면 $X$를 연속확률 변수라고 부르고 $f(x)$를 X의 확률밀도함수(probability density function, pdf)라고 부른다. $F(x) = \int_{-\infty}^xf(t)dt$</li>
  <li>확률변수를 명확히 하기 위해 $F_X(s), f_x(x)$로 쓰기도 한다.</li>
  <li>혼란이 없을 경우 $f_X(x)$대신 $p_X(x), p_x(x), p(x)$를 사용하기도 한다.</li>
  <li>$p(x) \ge 0, \int_{-\infty}^{\infty}p(x) = 1$</li>
</ul>

<h3 id="확률변수의-성질the-rules-of-probability">확률변수의 성질(The Rules of Probability)</h3>
<ul>
  <li>덧셈법칙(sum rule): 두 개의 확률변수 X,Y에 대한 확률은 Y에 대해서 이산확률변수인 경우에는 합을 구하고, 연속확률변수인 경우 적분을 하게 되면 X의 확률을 구할수 있다.(주변화)
    <ul>
      <li>$p(x) = \sum_Yp(X,Y)$</li>
    </ul>
  </li>
  <li>곱셈법칙(product rule):
    <ul>
      <li>$p(X,Y) = p(X \vert Y)p(Y) + p(Y \vert X)p(X)$</li>
    </ul>
  </li>
  <li>베이즈 확률(Baeys):
    <ul>
      <li>$p(Y \vert X) = \frac {p(X \vert Y)p(Y)}{\sum_Y p(X \vert Y) p(Y)} $</li>
      <li>$posterior = \frac {likelihood \times prior} {normalization}$
        <ul>
          <li>Posterior : 사후확률</li>
          <li>likelihood : 가능도(우도)</li>
          <li>prior : 사전확률</li>
          <li>normalization : Y와 상관없는 상수, X의 경계확률(marginal) $p(X)$</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="확률변수의-함수functions-of-random-variables">확률변수의 함수(Functions of Random Variables)</h3>
<ul>
  <li>확률변수 $X$의 함수 $Y = f(X)$도 확률변수이다(함수의 함수). 예를 들어 확률변수 $X$가 주(week)의 수로 표현되었다라고 할 때 일(day)의 수로 표현된 새로운 확률변수를 정의할 수 있다.
    <ul>
      <li>$Y = 7X$</li>
      <li>$P[14 \le 21] = P[2 \le 3]$</li>
    </ul>
  </li>
  <li>확률변수 X의 함수 $Y=g(X)$와 역함수 $w(Y) = X$가 주어졌을 때 다음이 성립한다.
    <ul>
      <li>$ p_y(y) = p_x(x)\vert {dx \over dy} \vert $</li>
    </ul>
  </li>
  <li>
    <p>k차원의 확률변수 벡터 $x = (x_1, …, x_k)$가 주어졌을 때, k개의 x에 관한 함수들 $y_i = g_i(x) for i = 1, …, k$는 새로운 확률변수벡터 $ y = (y_1, …, y_k)$를 정의한다. 간략하게 $y = g(x)$로 나타낼 수 있다. 만약, $y = g(x)$가 일대일(one-to-one)변환일 경우, y의 결합확률 밀도함수 (joint pdf)는 <br />
<img width="223" alt="스크린샷 2021-01-04 오전 11 49 49" src="https://user-images.githubusercontent.com/51064261/103496840-ffd81b80-4e82-11eb-963e-5e0703d69d36.png" /></p>
  </li>
  <li>Inverse CDF Technique
    <ul>
      <li>확률변수 $X$가 CDF $F_X(x)$를 가진다고 하자. 연속확률분포함수 U ~ UNIF(0,1)(0부터 1까지의 값이 1인 형태)의 함수로 정의되는 다음 확률변수 Y를 생각해보자.
        <ul>
          <li>$Y = F_X^{-1}(U)$</li>
        </ul>
      </li>
      <li>확률변수 $Y$는 확률변수 $X$와 동일한 분포를 따르게 된다.
        <ul>
          <li>$F_Y(y) = P[Y \le y] = P[F_X^{-1}(U) \le y] = P[U \le F_X(y)] = F_X(y)$</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="기대값expectations">기대값(Expectations)</h3>
<ul>
  <li>기대값: 확률분포 $p(X)$하에서 함수 $f(x)$의 평균값</li>
  <li>이산확률분포(discrete distribution) : $\mathbb E[f] = \sum_xp(x)f(x)$</li>
  <li>연속확률분포(continous distribution) : $\mathbb E[f] = \int p(x)f(x)$</li>
  <li>확률분포로부터 N개의 샘플을 추출해서 기댓값을 근사할 수 있다.
    <ul>
      <li>$\mathbb E[f] \approx {1 \over N}\sum_1^Nf(x_n)$</li>
    </ul>
  </li>
  <li>여러개 변수들의 함수
    <ul>
      <li>$\mathbb E_x[f(x, y)] = \sum_xf(x, y)p(x)$</li>
      <li>y에 대한 함수임을 상기할 것.</li>
      <li>$\mathbb E_{x,y}[f(x, y)] = \sum_y \sum_xf(x, y)p(x, y)$</li>
    </ul>
  </li>
  <li>조건부 기대값(conditional expectation):
    <ul>
      <li>$\mathbb E_x[f \vert y] = \sum_xf(x)p(x \vert y)$</li>
    </ul>
  </li>
</ul>

<h3 id="분산variance-공분산covariance">분산(Variance), 공분산(covariance)</h3>
<ul>
  <li>$f(x)$의 분산(variance): $f(x)$의 값들이 기댓값 $\mathbb E[f]$으로부터 흩어져 있는 정도
    <ul>
      <li>$var[f] = \mathbb E[(f(x) - \mathbb E[f(x)])^2] = \mathbb E[f(x)^2] - {\mathbb E[f(x)]}^2$</li>
      <li>$var[x] = \mathbb E[x^2] - \mathbb E[x]^2$</li>
    </ul>
  </li>
  <li>두 개의 확률변수 x, y에 대한 공분산(covariance)
    <ul>
      <li>$cov[x,y] = \mathbb E_{x,y}[(x - \mathbb E[x])(y - \mathbb E[y]) ] = \mathbb E_{x,y}[xy^T] - \mathbb E[x]\mathbb E[y^T]$</li>
      <li>$cov[x] \equiv cov[x,x]$</li>
    </ul>
  </li>
</ul>

<h3 id="빈도주의-대-베이지안frequentist-versus-bayesian">빈도주의 대 베이지안(Frequentist versus Bayesian)</h3>
<ul>
  <li>확률을 해석하는 두 가지 다른 관점: 빈도주의(frequentist), 베이지안(Bayesian)
    <ul>
      <li>빈도주의 : 반복가능한 사건들의 빈도수에 기반</li>
      <li>베이지안 : 불확실성을 정량적으로 표현</li>
    </ul>
  </li>
  <li>반복가능하지 않은 사건일 경우 : 북극 얼음이 이번 세기말까지 녹아 없어질 확률? 우리가 이미 알고 있는 정보(얼음이 녹고있는 속도)에 근거해 확률을 정량적으로 나타낼 수 있고, 새로 수집하는 정보에 따라 확률을 업데이트할 수 있다.</li>
  <li>모델의 파라미터 w(예를들어 다항식 곡선 근사문제에서의 계수 w)에 대한 우리의 지식을 확률적으로 나타내고 싶다면?
    <ul>
      <li>w에 대한 사전지식 $p(w) \to  $사전확률(prior)</li>
      <li>새로운 데이터 $D = (t_1, …, t_N)$를 관찰하고 난 뒤의 조건부확률 $p(D \vert w) \to $우도함수(likelihood function). 특정 w값에 대해 D의 관찰값이 얼마나 가능성이 있는지를 나타냄. w에 관한 함수임을 기억할 것.</li>
      <li>$p(w \vert D) = \frac {p(D \vert w)p(w)}{p(D)}$</li>
      <li>$p(w \vert D)$는 $D$를 관찰하고 난 뒤의 w에 대한 불확실성을 표현</li>
      <li>사후확률(posterior) $\propto$ 우도(likelihood) $\times$ 사전확률(prior)</li>
    </ul>
  </li>
  <li>반면, 빈도주의는 w가 고정된 파라미터이고 최대우도와 같은 ‘추정자(estimatior)’를 사용해서 그 값을 구한다. 구해진 파라미터의 불확실성은 부트스트랩(bootstrap) 방법을 써서 구할 수 있다.</li>
  <li>베이지안 관점의 장점
    <ul>
      <li>사전확률을 모델에 포함시킬 수 있다.</li>
      <li>동전을 던져서 세번 모두 앞면이 나왔을 때
        <ul>
          <li>최대우도 : 앞 면이 나올 확률은 1이 됨</li>
          <li>베이지안 : 극단적인 확률을 피할 수 있음</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="정규분포gaussian-distribution">정규분포(Gaussian Distribution)</h3>
<ul>
  <li>단일변수 x를 위한 가우시안 분포
    <ul>
      <li>$N(x \vert \mu, \sigma^2) = {1 \over (2\pi\sigma^2)^{1 \over 2}}exp(-{1 \over 2\sigma^2}(x - \mu)^2 )$</li>
    </ul>
  </li>
  <li>정규분포(Gaussian Distribution) : 기댓값(Expectation)
    <ul>
      <li>$E[x] = \int_{-\infty}^\infty N(x \vert \mu, \sigma^2)xdx = \mu$</li>
    </ul>
  </li>
  <li>정규분포(Gaussian Distribution) : 분산(Variance)
    <ul>
      <li>$var[x] = \sigma^2$</li>
    </ul>
  </li>
  <li>정규분포(Gaussian Distribution) : 최대우도해(Maximum Likelihood solution)
    <ul>
      <li>$X = (x_1, …, x_N)^T$가 독립적으로 같은 가우시안분포로부터 추출된 N개의 샘플들이라고 할 때,</li>
      <li>$p(X \vert \mu, \sigma^2) = p(x_1, …, x_N \vert \mu, \sigma^2) = \prod_{n=1}^N N(x_N\vert \mu,\sigma^2)$</li>
      <li>$\ln p(X \vert \mu, \sigma^2) = -{1\over 2 \sigma^2}\sum_{n=1}^N(x_n - \mu)^2 - {N \over 2}\ln\sigma^2 - {N \over 2}\ln(2\pi)$를 양변 $\mu$로 미분하여 0을 만드는 최대값을 찾음</li>
      <li>$\mu_{ML} = {1\over N}\sum_{n=1}^Nx_n$</li>
      <li>같은 방식으로,</li>
      <li>$\sigma_{ML}^2 = {1 \over N}\sum_{n=1}^N(x_n-\mu_{ML})^2$</li>
    </ul>
  </li>
</ul>
:ET